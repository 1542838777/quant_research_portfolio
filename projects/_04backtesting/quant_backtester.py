"""
é‡åŒ–å›æµ‹å™¨ - ä¸“ä¸šçº§å› å­ç­–ç•¥å›æµ‹å·¥å…·

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. å¤šå› å­ç­–ç•¥å›æµ‹å¯¹æ¯”
2. çœŸå®äº¤æ˜“æˆæœ¬å»ºæ¨¡
3. å®Œæ•´çš„é£é™©è°ƒæ•´æ”¶ç›Šåˆ†æ
4. å¯è§†åŒ–å’ŒæŠ¥å‘Šç”Ÿæˆ
5. å®ç›˜çº§æ•°æ®å¯¹é½å’ŒéªŒè¯

è®¾è®¡ç†å¿µï¼š
- é¢å‘å¯¹è±¡ï¼Œå¯æ‰©å±•
- æ•°æ®å®‰å…¨ï¼Œä¸¥æ ¼å¯¹é½éªŒè¯
- äº¤æ˜“æˆæœ¬çœŸå®å»ºæ¨¡
- ç»“æœå¯å¤ç°ï¼Œå¯è§£é‡Š
"""

import pandas as pd
import numpy as np
import vectorbt as vbt
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Optional, Tuple, Union
from dataclasses import dataclass
from pathlib import Path
import warnings
from datetime import datetime

from vectorbt.portfolio import CallSeqType, SizeType

from quant_lib.config.logger_config import setup_logger
from quant_lib.rebalance_utils import generate_rebalance_dates
from utils.math.math_utils import convert_to_sequential_percents

logger = setup_logger(__name__)
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
plt.rcParams['axes.unicode_minus'] = False


@dataclass
class BacktestConfig:
    """å›æµ‹é…ç½®å‚æ•°"""
    # ç­–ç•¥å‚æ•°
    top_quantile: float = 0.2  # åšå¤šåˆ†ä½æ•°é˜ˆå€¼ï¼ˆå‰20%ï¼‰
    rebalancing_freq: str = 'W'  # è°ƒä»“é¢‘ç‡ ('M'=æœˆæœ«, 'W'=å‘¨æœ«, 'Q'=å­£æœ«)

    # äº¤æ˜“æˆæœ¬å‚æ•°
    commission_rate: float = 0.0003  # ä½£é‡‘è´¹ç‡ï¼ˆä¸‡3ï¼‰
    slippage_rate: float = 0.0010  # æ»‘ç‚¹ç‡ï¼ˆåƒ1ï¼‰
    stamp_duty: float = 0.0010  # å°èŠ±ç¨ï¼ˆå•è¾¹ï¼Œå–å‡ºæ”¶å–ï¼‰
    min_commission: float = 5.0  # æœ€å°ä½£é‡‘ï¼ˆå…ƒï¼‰

    # å›æµ‹å‚æ•°
    initial_cash: float = 1000000.0  # åˆå§‹èµ„é‡‘ï¼ˆ100ä¸‡ï¼‰
    max_positions: int = 10  # æœ€å¤§æŒä»“æ•°é‡

    # é£æ§å‚æ•°
    max_weight_per_stock: float = 0.10  # å•è‚¡æœ€å¤§æƒé‡ï¼ˆ10%ï¼‰
    min_weight_threshold: float = 0.01  # æœ€å°æƒé‡é˜ˆå€¼ï¼ˆ1%ï¼‰

    # æ•°æ®éªŒè¯å‚æ•°
    min_data_coverage: float = 0.8  # æœ€å°æ•°æ®è¦†ç›–ç‡
    max_missing_consecutive_days: int = 5  # æœ€å¤§è¿ç»­ç¼ºå¤±å¤©æ•°

    #è‚¡ç¥¨æŒæœ‰ä¿¡æ¯ï¼š
    max_holding_days: int= 45


class DataValidator:
    """æ•°æ®éªŒè¯å™¨"""

    @staticmethod
    def validate_dataframes(price_df: pd.DataFrame, *factor_dfs: pd.DataFrame) -> Dict[str, any]:
        """
        éªŒè¯ä»·æ ¼æ•°æ®å’Œå› å­æ•°æ®çš„ä¸€è‡´æ€§
        
        Args:
            price_df: ä»·æ ¼æ•°æ®
            factor_dfs: å› å­æ•°æ®åˆ—è¡¨
            
        Returns:
            Dict: éªŒè¯ç»“æœç»Ÿè®¡
        """
        validation_results = {
            'is_valid': True,
            'errors': [],
            'warnings': [],
            'stats': {}
        }

        try:
            # æ£€æŸ¥ç´¢å¼•ç±»å‹
            if not isinstance(price_df.index, pd.DatetimeIndex):
                validation_results['errors'].append("ä»·æ ¼æ•°æ®ç´¢å¼•å¿…é¡»æ˜¯DatetimeIndex")
                validation_results['is_valid'] = False

            # æ£€æŸ¥æ•°æ®å¯¹é½
            reference_index = price_df.index
            reference_columns = price_df.columns

            for i, factor_df in enumerate(factor_dfs):
                factor_name = f"å› å­{i + 1}"

                # ç´¢å¼•å¯¹é½æ£€æŸ¥
                if not factor_df.index.equals(reference_index):
                    missing_dates = reference_index.difference(factor_df.index)
                    if len(missing_dates) > 0:
                        validation_results['warnings'].append(
                            f"{factor_name}ç¼ºå¤±{len(missing_dates)}ä¸ªäº¤æ˜“æ—¥"
                        )

                # åˆ—å¯¹é½æ£€æŸ¥
                if not factor_df.columns.equals(reference_columns):
                    missing_stocks = reference_columns.difference(factor_df.columns)
                    if len(missing_stocks) > 0:
                        validation_results['warnings'].append(
                            f"{factor_name}ç¼ºå¤±{len(missing_stocks)}åªè‚¡ç¥¨"
                        )

            # ç»Ÿè®¡ä¿¡æ¯
            validation_results['stats'] = {
                'date_range': (price_df.index.min(), price_df.index.max()),
                'trading_days': len(price_df.index),
                'stock_count': len(price_df.columns),
                'data_coverage': (1 - price_df.isnull().sum().sum() / price_df.size) * 100
            }

            logger.info(f"æ•°æ®éªŒè¯å®Œæˆ: {validation_results['stats']}")

        except Exception as e:
            validation_results['errors'].append(f"éªŒè¯è¿‡ç¨‹å¼‚å¸¸: {str(e)}")
            validation_results['is_valid'] = False

        return validation_results

    @staticmethod
    def align_dataframes(price_df: pd.DataFrame, *factor_dfs: pd.DataFrame) -> Tuple[pd.DataFrame, ...]:
        """
        å¯¹é½ä»·æ ¼æ•°æ®å’Œå› å­æ•°æ®
        
        Args:
            price_df: ä»·æ ¼æ•°æ®
            factor_dfs: å› å­æ•°æ®åˆ—è¡¨
            
        Returns:
            Tuple: å¯¹é½åçš„æ•°æ®æ¡†åˆ—è¡¨
        """
        # ä½¿ç”¨vectorbtçš„å¯¹é½åŠŸèƒ½
        aligned_data = vbt.base.reshape_fns.broadcast(price_df, *factor_dfs,
                                                      keep_pd=True,
                                                      align_index=True,
                                                      align_columns=True)

        logger.info(f"æ•°æ®å¯¹é½å®Œæˆï¼Œæœ€ç»ˆç»´åº¦: {aligned_data[0].shape}")
        return aligned_data


class StrategySignalGenerator:
    """ç­–ç•¥ä¿¡å·ç”Ÿæˆå™¨"""

    @staticmethod
    def generate_long_signals(
            factor_df: pd.DataFrame,
            config: BacktestConfig
    ) -> pd.DataFrame:
        """
        ç”Ÿæˆåšå¤šä¿¡å·

        Args:
            factor_df: å› å­æ•°æ®
            config: å›æµ‹é…ç½®

        Returns:
            pd.DataFrame: æŒä»“ä¿¡å·ï¼ˆTrue=æŒæœ‰ï¼ŒFalse=ä¸æŒæœ‰ï¼‰
        """
        # 1. è®¡ç®—æ¯æ—¥æ’åç™¾åˆ†ä½ï¼ˆè¶Šå¤§æ’åè¶Šé å‰ï¼‰
        ranks = factor_df.rank(axis=1, pct=True, method='average', na_option='keep')

        # 2. ç¡®å®šåšå¤šä¿¡å·ï¼ˆæ’ååœ¨å‰top_quantileï¼‰
        long_signals_raw = ranks >= (1 - config.top_quantile)

        # 3. æŒ‰è°ƒä»“é¢‘ç‡è¿›è¡Œé‡é‡‡æ ·
        # .resample().last() è·å–æ¯ä¸ªå‘¨æœŸæœ€åä¸€å¤©çš„ä¿¡å·
        # .reindex().ffill() å°†ä¿¡å·å‰å¡«å……åˆ°æ¯ä¸ªäº¤æ˜“æ—¥
        rebalance_signals = long_signals_raw.resample(config.rebalancing_freq).last()
        final_signals = rebalance_signals.reindex(factor_df.index, method='ffill')

        # 4. æ§åˆ¶æœ€å¤§æŒä»“æ•°é‡
        if config.max_positions > 0:
            final_signals = StrategySignalGenerator._limit_positions(
                final_signals, ranks, config.max_positions
            )

        logger.info(f"ä¿¡å·ç”Ÿæˆå®Œæˆï¼Œå¹³å‡æŒä»“æ•°: {final_signals.sum(axis=1).mean():.1f}")
        return final_signals.fillna(False)

    @staticmethod
    def _limit_positions(signals: pd.DataFrame, ranks: pd.DataFrame, max_positions: int) -> pd.DataFrame:
        """
        é™åˆ¶æœ€å¤§æŒä»“æ•°é‡ï¼Œä¼˜å…ˆé€‰æ‹©æ’åæœ€é«˜çš„è‚¡ç¥¨
        
        Args:
            signals: åŸå§‹ä¿¡å·
            ranks: æ’åæ•°æ®
            max_positions: æœ€å¤§æŒä»“æ•°
            
        Returns:
            pd.DataFrame: é™åˆ¶åçš„ä¿¡å·
        """
        limited_signals = pd.DataFrame(False, index=signals.index, columns=signals.columns)

        for date in signals.index:
            date_signals = signals.loc[date]
            date_ranks = ranks.loc[date]

            if date_signals.sum() > max_positions:
                # é€‰æ‹©æ’åæœ€é«˜çš„max_positionsåªè‚¡ç¥¨
                valid_stocks = date_signals[date_signals].index
                top_stocks = date_ranks[valid_stocks].nlargest(max_positions).index
                limited_signals.loc[date, top_stocks] = True
            else:
                limited_signals.loc[date] = date_signals

        return limited_signals



    @staticmethod
    def generate_long_holding_signals(factor_df: pd.DataFrame, price_df, config: BacktestConfig) -> pd.DataFrame:
        """
        ç”Ÿæˆæ¯æ—¥ç›®æ ‡"æŒä»“"å¸ƒå°”çŸ©é˜µï¼Œç¡®ä¿æ»¡ä»“è¿ä½œ
        """
        # è®¡ç®—æ¯æ—¥æ’å
        ranks = factor_df.rank(axis=1, pct=True, method='average', na_option='keep')

        # ç”Ÿæˆæ¯æ—¥æŒä»“ä¿¡å·ï¼Œè€Œä¸æ˜¯åªåœ¨è°ƒä»“æ—¥
        daily_holding_signals = pd.DataFrame(False, index=factor_df.index, columns=factor_df.columns)
        # è·å–è°ƒä»“æ—¥æœŸ
        rebalance_dates = ranks.copy().reindex(generate_rebalance_dates(ranks.index,config.rebalancing_freq)).dropna(how='all').index

        # å½“å‰æŒä»“ç»„åˆï¼ˆåœ¨è°ƒä»“é—´éš”æœŸé—´ä¿æŒä¸å˜ï¼‰
        current_positions = None

        for date in factor_df.index:
            # æ£€æŸ¥æ˜¯å¦ä¸ºè°ƒä»“æ—¥
            is_rebalance_day = date in rebalance_dates

            if is_rebalance_day:
                # è°ƒä»“æ—¥ï¼šé‡æ–°é€‰æ‹©è‚¡ç¥¨
                daily_valid_ranks = ranks.loc[date].dropna()

                if len(daily_valid_ranks) > 0:
                    # è®¡ç®—ç›®æ ‡æŒä»“æ•°
                    num_to_select = int(np.ceil(len(daily_valid_ranks) * config.top_quantile))
                    if config.max_positions:
                        num_to_select = min(num_to_select, config.max_positions)

                    # é€‰æ‹©æ’åæœ€é«˜çš„è‚¡ç¥¨
                    chosen_stocks = daily_valid_ranks.nlargest(num_to_select).index
                    current_positions = chosen_stocks
                    # logger.info(f"è°ƒä»“æ—¥{date.strftime('%Y-%m-%d')}: é€‰æ‹©{len(chosen_stocks)}åªè‚¡ç¥¨")

            if current_positions is not None: #å…¶å®å°±æ˜¯å˜ç›¸çš„ffill ï¼Œä¿æŒè¿™æ¬¡è°ƒä»“åŠåé¢nå¤©åŒçŠ¶æ€ ï¼Œç›´åˆ°ä¸‹ä¸€æ¬¡è°ƒä»“ï¼
                #æœ€æ–°æ³¨é‡Šï¼Œäº¤ç»™ä¸‹æ¸¸ å»åˆ¤æ–­
                # # æ£€æŸ¥è‚¡ç¥¨ æ˜¯å¦å¯äº¤æ˜“==>ï¼ˆæœ‰ä»·æ ¼æ•°æ®ï¼‰
                # current_with_price_positions = price_df.loc[date, current_positions].notna()
                # tradable_positions = current_positions[current_with_price_positions]
                daily_holding_signals.loc[date, current_positions] = True

        # éªŒè¯æŒä»“ä¿¡å·è´¨é‡
        daily_positions = daily_holding_signals.sum(axis=1)
        avg_positions = daily_positions.mean()
        zero_position_days = (daily_positions == 0).sum()

        logger.info(f"  å¹³å‡æ¯æ—¥æŒä»“æ•°: {avg_positions:.1f}")
        logger.info(f"  é›¶æŒä»“å¤©æ•°: {zero_position_days}/{len(daily_positions)}")
        logger.info(f"  æŒä»“è¦†ç›–ç‡: {(1 - zero_position_days / len(daily_positions)):.1%}")

        if zero_position_days > len(daily_positions) * 0.1:  # è¶…è¿‡10%çš„æ—¥å­æ²¡æœ‰æŒä»“
            logger.warning(f"âš ï¸ æŒä»“ä¿¡å·è´¨é‡å·®ï¼š{zero_position_days}å¤©æ— æŒä»“")
        else:
            logger.info(f"âœ… æŒä»“ä¿¡å·è´¨é‡è‰¯å¥½")

        return daily_holding_signals

    @staticmethod
    def generate_rebalancing_signals(holding_signals: pd.DataFrame, force_exit_limit: int = None) -> Tuple[
        pd.DataFrame, pd.DataFrame]:
        """
        å°†"æŒä»“"çŸ©é˜µè½¬æ¢ä¸ºç²¾ç¡®çš„"ä¹°å…¥"å’Œ"å–å‡º"ä¿¡å·çŸ©é˜µã€‚
        - å¢åŠ äº†å¼ºåˆ¶ç±»å‹è½¬æ¢ï¼Œå½»åº•è§£å†³ 'invert' ufunc TypeError é—®é¢˜ã€‚
        - æ–°å¢60å¤©å¼ºåˆ¶å–å‡ºé€»è¾‘ æ…ç”¨ï¼ ä¿æŒå‡½æ•°å•ä¸€
        """

        # ã€æ ¸å¿ƒä¿®æ­£ã€‘åœ¨ä½¿ç”¨ ~ æ“ä½œç¬¦ä¹‹å‰ï¼Œè¿›è¡Œä¸¥æ ¼çš„ç±»å‹å’Œç©ºå€¼å¤„ç†

        # 1. ç¡®ä¿å½“å‰æŒä»“ä¿¡å·æ˜¯å¸ƒå°”å‹
        current_holdings = holding_signals.astype(bool)

        # 2. å¯¹å‰ä¸€å¤©çš„æŒä»“ä¿¡å·ï¼Œå…ˆå¡«å……ç§»ä½äº§ç”Ÿçš„NaNï¼Œå†å¼ºåˆ¶è½¬ä¸ºå¸ƒå°”å‹
        prev_holdings = holding_signals.vbt.fshift(1).fillna(False).astype(bool)

        # 3. åŸºç¡€ä¹°å–ä¿¡å·
        entries = current_holdings & ~prev_holdings
        exits = ~current_holdings & prev_holdings

        # å¼ºåˆ¶å–å‡ºé€»è¾‘ - ç”¨äºè°ƒè¯•äº¤æ˜“æ‰§è¡Œé—®é¢˜
        forced_exits=None
        # logger.info("  -> æ­£åœ¨æ·»åŠ 60å¤©å¼ºåˆ¶å–å‡ºé€»è¾‘...")
        if force_exit_limit:
            # åˆ›å»ºæŒä»“å¤©æ•°è®¡æ•°å™¨
            holding_days = pd.DataFrame(0, index=holding_signals.index, columns=holding_signals.columns)
            forced_exits = pd.DataFrame(False, index=holding_signals.index, columns=holding_signals.columns)
            # forå¾ªç¯ å¡«å……å¤©æ•°ï¼ ä»¥åŠåˆ¤æ–­å¤©æ•°è¶…è¿‡limit ç»™å‡ºå¼ºåˆ¶å–å‡ºä¿¡å·
            for i in range(1, len(holding_signals)):
                # å¯¹äºæŒç»­æŒæœ‰çš„è‚¡ç¥¨ï¼Œå¤©æ•°+1
                continuing_holds = current_holdings.iloc[i] & prev_holdings.iloc[i]
                holding_days.iloc[i] = np.where(continuing_holds,
                                                holding_days.iloc[i - 1] + 1,
                                                0)

                # å¯¹äºæ–°ä¹°å…¥çš„è‚¡ç¥¨ï¼Œå¤©æ•°é‡ç½®ä¸º1
                new_entries = entries.iloc[i]  # è¿™ä¸ªä¸ºtrueï¼Œé‚£ä¹ˆæ˜¨å¤©ä¸€å®šæ˜¯falseï¼Œæ²¡æ¯›ç—…
                holding_days.iloc[i] = np.where(new_entries, 1, holding_days.iloc[i])

                # å¼ºåˆ¶å–å‡ºæŒæœ‰è¶…è¿‡180å¤©çš„è‚¡ç¥¨ (180å¤©)
                force_exit_mask = holding_days.iloc[i] >= force_exit_limit
                forced_exits.iloc[i] = force_exit_mask & current_holdings.iloc[i]
                logger.info(f"  -> å¼ºåˆ¶è¶…è¿‡{force_exit_limit}å¤©å–å‡ºè§¦å‘æ¬¡æ•°: {forced_exits.sum().sum()}")

        final_exits = exits
        # 5. åˆå¹¶åŸæœ‰å–å‡ºä¿¡å·å’Œå¼ºåˆ¶å–å‡ºä¿¡å·
        if force_exit_limit:
            final_exits = exits | forced_exits
        return entries, final_exits


class TradingCostCalculator:
    """äº¤æ˜“æˆæœ¬è®¡ç®—å™¨ - é‡æ„ç‰ˆæœ¬"""

    @staticmethod
    def get_single_side_costs(config: BacktestConfig) -> Dict[str, float]:
        """
        è·å–å•è¾¹äº¤æ˜“æˆæœ¬
        
        Args:
            config: å›æµ‹é…ç½®
            
        Returns:
            Dict: å•è¾¹æˆæœ¬å­—å…¸
        """
        # åŸºç¡€å•è¾¹æˆæœ¬ (ä½£é‡‘)
        base_commission = config.commission_rate

        # å•è¾¹æ»‘ç‚¹
        single_slippage = config.slippage_rate

        # å°èŠ±ç¨åªåœ¨å–å‡ºæ—¶æ”¶å–ï¼Œæˆ‘ä»¬å°†å…¶åˆ†æ‘Šåˆ°ä¹°å–ä¸¤è¾¹
        # æˆ–è€…åŒ…å«åœ¨ä¸€ä¸ªç¨é«˜çš„ç»¼åˆè´¹ç‡ä¸­
        adjusted_commission = base_commission + (config.stamp_duty / 2)  # åˆ†æ‘Šå°èŠ±ç¨

        costs = {
            'commission': adjusted_commission,
            'slippage': single_slippage,
            'combined_fee': adjusted_commission  # vectorbtçš„feeså‚æ•°
        }

        logger.info(f"å•è¾¹äº¤æ˜“æˆæœ¬: ä½£é‡‘{adjusted_commission:.4f}, æ»‘ç‚¹{single_slippage:.4f}")
        return costs


class QuantBacktester:
    """é‡åŒ–å›æµ‹å™¨ä¸»ç±»"""

    def __init__(self, config: Optional[BacktestConfig] = None):
        """
        åˆå§‹åŒ–å›æµ‹å™¨
        
        Args:
            config: å›æµ‹é…ç½®ï¼ŒNoneæ—¶ä½¿ç”¨é»˜è®¤é…ç½®
        """
        self.config = config or BacktestConfig()
        self.validator = DataValidator()
        self.signal_generator = StrategySignalGenerator()
        self.cost_calculator = TradingCostCalculator()

        # å­˜å‚¨å›æµ‹ç»“æœ
        self.portfolios: Dict[str, any] = {}
        self.validation_results: Dict = {}

        logger.info("QuantBacktesteråˆå§‹åŒ–å®Œæˆ")
        logger.info(f"é…ç½®å‚æ•°: {self.config}")

    def prepare_data(
            self,
            price_df: pd.DataFrame,
            factor_dict: Dict[str, pd.DataFrame]
    ) -> Tuple[pd.DataFrame, Dict[str, pd.DataFrame]]:
        """
        å‡†å¤‡å’ŒéªŒè¯å›æµ‹æ•°æ®
        
        Args:
            price_df: ä»·æ ¼æ•°æ®
            factor_dict: å› å­æ•°æ®å­—å…¸ {"å› å­å": DataFrame}
            
        Returns:
            Tuple: (å¯¹é½åçš„ä»·æ ¼æ•°æ®, å¯¹é½åçš„å› å­æ•°æ®å­—å…¸)
        """
        logger.info(f"å¼€å§‹å‡†å¤‡æ•°æ®ï¼Œä»·æ ¼æ•°æ®ç»´åº¦: {price_df.shape}")
        logger.info(f"å› å­æ•°é‡: {len(factor_dict)}")

        # éªŒè¯æ•°æ®
        factor_dfs = list(factor_dict.values())
        self.validation_results = self.validator.validate_dataframes(price_df, *factor_dfs)

        if not self.validation_results['is_valid']:
            raise ValueError(f"æ•°æ®éªŒè¯å¤±è´¥: {self.validation_results['errors']}")

        if self.validation_results['warnings']:
            for warning in self.validation_results['warnings']:
                logger.warning(warning)

        # å¯¹é½æ•°æ®
        aligned_data = self.validator.align_dataframes(price_df, *factor_dfs)
        aligned_price = aligned_data[0]
        aligned_factors = {
            name: aligned_data[i + 1]
            for i, name in enumerate(factor_dict.keys())
        }

        logger.info(f"æ•°æ®å‡†å¤‡å®Œæˆï¼Œæœ€ç»ˆç»´åº¦: {aligned_price.shape}")
        return aligned_price, aligned_factors

    def _generate_improved_signals(
            self,
            holding_signals: pd.DataFrame,
            price_df: pd.DataFrame,
            max_holding_days: int = None,
            retry_buy_limit: int = 3  # ä¹°å…¥é‡è¯•çš„æœ‰æ•ˆæœŸï¼ˆå¤©æ•°ï¼‰
    ):
        """
               -   a_holdings çŠ¶æ€å˜é‡ï¼Œç²¾ç¡®è¿½è¸ªæ¯æ—¥çœŸå®æŒä»“ã€‚

               - å½»åº•è§£å†³â€œè´Ÿæ•°æŒä»“â€ã€â€œåƒµå°¸ä¿¡å·â€ã€â€œå›å£°ä¿¡å·â€ç­‰æ‰€æœ‰çŠ¶æ€ç®¡ç†Bugã€‚
               - è¿™æ˜¯åœ¨ for å¾ªç¯æ¡†æ¶å†…æœ€ç¨³å¥çš„å®ç°ã€‚
               buy_num_should_base_on_sell_num: å–å‡ºå»å¤šå°‘åªï¼Œå†³å®šèƒ½ä¹°å…¥å¤šå°‘åªï¼ˆåœºæ™¯ï¼šæ¯”å¦‚ä¸€å¤©10è‚¡ç¥¨éƒ½åœç‰Œï¼Œä½ å“ªé‡Œè¿˜æœ‰é’±ä¹°å…¥ï¼ ä»Šæ—¥å¯ä¹°å…¥æ•°é‡=å‰ä¸€å¤©ç©ºä½™å¯è´­å…¥è‚¡ç¥¨æ•°é‡+ä»Šå¤©å·²ç»å–å‡ºæ•°é‡ï¼ æ€è€ƒæ˜å¤©æ¥ç€ä¹°å—ï¼Ÿä¸æ¥ç€ä¹°ï¼šé‚£è¿™åªè‚¡ç¥¨å¯èƒ½å°±é”™è¿‡äº†ï¼æ¥ç€ä¹°ï¼šæœ‰å¯èƒ½æç«¯æƒ…å†µ20å¤©åæ‰ä¹°å…¥ï¼ï¼Œä½†æ˜¯å·²ç»å¾ˆæ™šäº†ï¼ä¹Ÿæ˜¯æœ‰é—®é¢˜ï¼ ä½ æœ‰ä»€ä¹ˆå¥½çš„æ–¹æ¡ˆå—
               #æœ€æ–°å®æµ‹ç»“è®ºï¼šbuy_num_should_base_on_sell_num æˆ‘æƒ³å¤šäº†ï¼Œvector å·²ç»å¸®æˆ‘æƒ³åˆ°äº†ï¼ï¼Œè‡ªå·±åšäº†åˆ¤æ–­ï¼Œä¹°ä¸è¿›å» ä¸ä¼šå¼ºè¡Œä¹°çš„ï¼ï¼ï¼ï¼
               #é—®é¢˜ï¼šä½†æ˜¯vectoré»˜è®¤æ˜¯ä¸ä¼šå†æ¬¡è´­å…¥çš„ï¼Œæ‰”äº†å¤šå¯æƒœ è§£å†³åŠæ³•ï¼š
               - æ–°å¢â€œå¾…ä¹°æ¸…å•â€é€»è¾‘ï¼Œå¤„ç†å› åœç‰Œæˆ–èµ„é‡‘ä¸è¶³è€Œå¤±è´¥çš„ä¹°å…¥ä¿¡å·ã€‚
                - ä¿¡å·å…·æœ‰â€œæœ‰æ•ˆæœŸâ€ï¼Œè¿‡æœŸä½œåºŸã€‚ ï¼ˆæœ€å¤šåªè®©é‡è¯•nå¤©
               """
        logger.info(f"ã€V7 æœ€ç»ˆç‰ˆã€‘å¼€å§‹ç”Ÿæˆä¿¡å·ï¼Œæœ€å¤§æŒä»“: {max_holding_days}, ä¹°å…¥é‡è¯•æœŸ: {retry_buy_limit}å¤©")

        # --- åˆå§‹åŒ– ---
        entries = pd.DataFrame(False, index=holding_signals.index, columns=holding_signals.columns)
        exits = pd.DataFrame(False, index=holding_signals.index, columns=holding_signals.columns)

        # --- çŠ¶æ€å˜é‡ ---
        # ã€æ ¸å¿ƒã€‘â€œå®é™…æŒä»“â€çŠ¶æ€ï¼Œä½œä¸ºå¾ªç¯å†…éƒ¨çš„åœ°é¢å®å†µ
        actual_holdings = pd.Series(False, index=holding_signals.columns)

        # æŒä»“å¤©æ•°è®¡æ•°å™¨
        holding_days = pd.Series(0, index=holding_signals.columns)

        # â€œå¾…å–æ¸…å•â€ï¼Œè¿½è¸ªéœ€è¦å–å‡ºä½†å¯èƒ½è¢«å»¶è¿Ÿçš„è‚¡ç¥¨
        pending_exits_tracker = pd.Series(False, index=holding_signals.columns)

        # â€œå¾…ä¹°æ¸…å•â€å’Œä»»åŠ¡æœ‰æ•ˆæœŸè®¡æ•°å™¨
        pending_buys_tracker = pd.Series(False, index=holding_signals.columns)
        pending_buys_age = pd.Series(0, index=holding_signals.columns)

        # --- é€æ—¥å¾ªç¯ç”Ÿæˆä¿¡å· ---
        for i in range(len(holding_signals)):
            curr_holdings_plan = holding_signals.iloc[i]

            # --- 1. çŠ¶æ€æ›´æ–°ï¼ˆæ¯æ—¥å¼€å§‹æ—¶ï¼‰---
            # a. å¯¹â€œå¾…ä¹°æ¸…å•â€ä¸Šçš„ä»»åŠ¡è¿›è¡Œâ€œè€åŒ–â€ï¼Œå¹¶ä½œåºŸâ€œè¿‡æœŸâ€ä»»åŠ¡
            if pending_buys_tracker.any():
                pending_buys_age[pending_buys_tracker] += 1
                expired_buys = pending_buys_age > retry_buy_limit
                pending_buys_tracker[expired_buys] = False #ä¸ç”¨å†ä¹°å…¥äº†
                pending_buys_age[expired_buys] = 0# å¹´é¾„ä¹Ÿè·Ÿç€ç½®ä¸º0 åæ­£ä¸ä¹°äº†

            # b. æ›´æ–°æŒä»“å¤©æ•°: åªä¸ºå®é™…æŒæœ‰çš„è‚¡ç¥¨ç´¯åŠ å¤©æ•°
            holding_days[actual_holdings] += 1   #æœ‰ç‚¹è·³è·ƒã€‚ç–‘é—®ï¼šä¸‡ä¸€ä»Šå¤©æ˜¯å–å‡ºä¿¡å·ï¼Œä½ è¿™é‡ŒåŠ ä¸€æ²¡æœ‰å½±å“å—ï¼Ÿç­”ï¼šç¡®å®æ²¡æœ‰ï¼Œå› ä¸ºæœ€åï¼šholding_days[actual_holdings=0

            # --- 2. ã€æ”¶é›†æ„å›¾ã€‘è®¡ç®—æ‰€æœ‰å¯èƒ½çš„â€œå–å‡ºæ„å›¾â€ ---
            # a. æ­£å¸¸è°ƒä»“å–å‡º: è®¡åˆ’ä¸å†æŒæœ‰ï¼Œä½†æˆ‘ä»¬å®é™…è¿˜æŒæœ‰
            normal_exits_intent = ~curr_holdings_plan & actual_holdings

            # b. å¼ºåˆ¶æŒæœ‰æœŸæ»¡å–å‡º: è¾¾åˆ°æœ€å¤§å¤©æ•°ä¸”ä»åœ¨å®é™…æŒæœ‰
            force_exit_intent = pd.Series(False, index=holding_signals.columns)
            if max_holding_days is not None:
                force_exit_intent = (holding_days >= max_holding_days) & actual_holdings

            # c. åˆå¹¶æ‰€æœ‰å–å‡ºæ„å›¾ï¼ˆåŒ…æ‹¬æ˜¨æ—¥æœªå®Œæˆçš„ï¼‰
            total_intent_to_sell = normal_exits_intent | force_exit_intent | pending_exits_tracker

            # --- 3. ã€æ”¶é›†æ„å›¾ã€‘è®¡ç®—æ‰€æœ‰å¯èƒ½çš„â€œä¹°å…¥æ„å›¾â€ ---
            # a. ä»Šå¤©æ–°äº§ç”Ÿçš„ä¹°å…¥æ„å›¾: è®¡åˆ’è¦æŒæœ‰ï¼Œä½†æˆ‘ä»¬å®é™…æ²¡æœ‰æŒæœ‰
            new_buy_intent = curr_holdings_plan & ~actual_holdings

            # b. åˆå¹¶â€œå¾…ä¹°æ¸…å•â€ä¸­çš„ä»»åŠ¡ï¼Œå½¢æˆâ€œä»Šæ—¥æ€»ä¹°å…¥æ„å›¾â€
            total_intent_to_buy = new_buy_intent | pending_buys_tracker

            # --- 4. ã€å¤„ç†æ‰§è¡Œã€‘ç»“åˆå¸‚åœºç°å®ï¼ˆåœç‰Œï¼‰ï¼Œå†³å®šä»Šå¤©å®é™…çš„äº¤æ˜“ ---
            is_tradable_today = price_df.iloc[i].notna()

            executable_exits = total_intent_to_sell & is_tradable_today
            executable_entries = total_intent_to_buy & is_tradable_today

            # è®°å½•æœ€ç»ˆä¿¡å·
            exits.iloc[i] = executable_exits
            entries.iloc[i] = executable_entries

            # --- 5.ã€æ›´æ–°çŠ¶æ€ã€‘ä¸ºâ€œæ˜å¤©â€å‡†å¤‡å¥½æ‰€æœ‰çŠ¶æ€å˜é‡ ---
            # a. æ›´æ–°â€œå®é™…æŒä»“â€
            actual_holdings = (actual_holdings | executable_entries) & ~executable_exits

            # b. æ›´æ–°â€œå¾…å–æ¸…å•â€
            pending_exits_tracker = total_intent_to_sell & ~is_tradable_today

            # c. æ›´æ–°â€œå¾…ä¹°æ¸…å•â€å’Œâ€œå¹´é¾„â€
            pending_buys_tracker = total_intent_to_buy & ~executable_entries
            pending_buys_age[~pending_buys_tracker] = 0  # ä¸åœ¨æ¸…å•ä¸Šçš„ï¼Œå¹´é¾„å½’é›¶ ï¼ˆéå¾…ä¹°çš„ï¼Œ==0
            # æ–°åŠ å…¥æ¸…å•çš„ï¼Œå¹´é¾„ä»1å¼€å§‹ï¼ˆå› ä¸ºä»Šå¤©å·²ç»ç®—ä¸€å¤©äº†ï¼‰
            newly_pending_buys_mask = pending_buys_tracker & (pending_buys_age == 0)
            pending_buys_age[newly_pending_buys_mask] = 1

            # d. æ›´æ–°â€œæŒä»“å¤©æ•°â€
            # å¯¹äºä»Šå¤©æ–°ä¹°å…¥çš„ï¼Œå¤©æ•°è®¾ä¸º1ï¼›å¯¹äºä»Šå¤©å–å‡ºçš„ï¼Œå¤©æ•°å½’é›¶
            holding_days[executable_entries] = 1
            holding_days[executable_exits] = 0

        # --- æœŸæœ«å¤„ç† ---
        # åœ¨æœ€åä¸€ä¸ªäº¤æ˜“æ—¥ï¼Œå¼ºåˆ¶æ¸…ä»“æ‰€æœ‰ä»åœ¨æŒæœ‰çš„ã€æˆ–ä»åœ¨å¾…å–æ¸…å•ä¸Šçš„è‚¡ç¥¨
        final_holdings = actual_holdings | pending_exits_tracker
        is_tradable_last_day = price_df.iloc[-1].notna()
        exits.iloc[-1] = exits.iloc[-1] | (final_holdings & is_tradable_last_day)

        logger.info(f"ä¿¡å·ç”Ÿæˆå®Œæˆ: ä¹°å…¥ä¿¡å·({entries.sum().sum()})ä¸ª, æ€»å–å‡ºä¿¡å·({exits.sum().sum()})ä¸ª")
        return entries, exits


    def run_backtest_old(
            self,
            price_df: pd.DataFrame,
            factor_dict: Dict[str, pd.DataFrame]
    ) -> Dict[str, any]:
        # 1. æ•°æ®å‡†å¤‡
        all_dfs = [price_df] + list(factor_dict.values())
        aligned_dfs = vbt.base.reshape_fns.broadcast(*all_dfs, keep_pd=True, align_index=True, align_columns=True)

        aligned_price = aligned_dfs[0]
        aligned_factors = {name: df for name, df in zip(factor_dict.keys(), aligned_dfs[1:])}
        logger.info(f"æ•°æ®å¯¹é½å®Œæˆï¼Œæœ€ç»ˆç»´åº¦: {aligned_price.shape}")
        # 2. é€ä¸ªå› å­å›æµ‹
        for factor_name, factor_data in aligned_factors.items():
            logger.info(f"ğŸš€ å¼€å§‹å›æµ‹å› å­: {factor_name}")
            # 3. ä¿¡å·ç”Ÿæˆæµæ°´çº¿
            # é¦–å…ˆï¼Œç”Ÿæˆæ¯æ—¥çš„ç›®æ ‡æŒä»“çŠ¶æ€ å…¨æ˜¯true false è¡¨ç¤ºå½“æ—¥rankæƒ…å†µçš„true flase
            holding_signals = self.signal_generator.generate_long_holding_signals(factor_data, aligned_price,
                                                                                  self.config)

            origin_weights_df = self.get_position_weights_by_per_weight(holding_signals)
            self.myself_debug_data(origin_weights_df)
            #ç…§é¡¾vector ä¸“é—¨ä¸ºä»–ç®—æœ¯ï¼
            weights_df = convert_to_sequential_percents(origin_weights_df)
            # è®¡ç®—åˆç†çš„ç»¼åˆäº¤æ˜“è´¹ç”¨
            # ä¹°å…¥æˆæœ¬: ä½£é‡‘(ä¸‡3) + æ»‘ç‚¹(åƒ1) = 0.0003 + 0.001 = 0.0013
            # å–å‡ºæˆæœ¬: ä½£é‡‘(ä¸‡3) + å°èŠ±ç¨(åƒ1) + æ»‘ç‚¹(åƒ1) = 0.0003 + 0.001 + 0.001 = 0.0023
            # å¹³å‡åŒè¾¹æˆæœ¬: (0.0013 + 0.0023) / 2 = 0.0018
            comprehensive_fee_rate = (
                    self.config.commission_rate +  # ä½£é‡‘ 0.0003
                    self.config.slippage_rate +  # æ»‘ç‚¹ 0.001
                    self.config.stamp_duty / 2  # å°èŠ±ç¨åˆ†æ‘Š 0.0005
            )
            # æ”¹è¿›é€€å‡ºä¿¡å·ç”Ÿæˆ - ç¡®ä¿åœ¨æ—¶é—´çª—å£ç»“æŸæ—¶å¼ºåˆ¶é€€å‡º (è¿™æ ·åšï¼Œåªæ˜¯ä¸ºäº†ç®€å•ç›´è§‚çœ‹å‡ºæˆ‘çš„ç­–ç•¥æ•ˆæœï¼
            improved_entries, improved_exits = self._generate_improved_signals(
                holding_signals, aligned_price, max_holding_days=self.config.max_holding_days
            )
            # ã€æ–°å¢è°ƒè¯•ã€‘æ£€æŸ¥ä¿¡å·çš„è¯¦ç»†æƒ…å†µ
            self.debug_signal_generation(holding_signals, self.config, improved_entries, improved_exits, origin_weights_df,0,len(holding_signals)-1)

            # 1. æ£€æŸ¥å®é™…çš„äº¤æ˜“è®°å½•
            portfolio = vbt.Portfolio.from_signals(
                call_seq='auto',  # first sell then buy å®æµ‹! å¿…é¡»é…ç½®ï¼
                group_by=True,  # å¿…é¡»é…ç½®
                cash_sharing=True,  # å¿…é¡»é…ç½®

                size_type="percent",  # å®æµ‹ï¼ æŒä»“é‡‘é¢ä¸ºç™¾åˆ†æ¯”
                size=weights_df,

                #è‡ªå®šä¹‰df ä»·æ ¼æ•°æ®
                close=aligned_price,
                #ä¿¡å·
                entries=improved_entries,
                exits=improved_exits,

                #äº¤æ˜“è¿‡ç¨‹ä¸­æŒ‡æ ‡
                init_cash=self.config.initial_cash,
                fees=comprehensive_fee_rate,
                freq='D' #å½¢å®¹ä»·æ ¼çš„
            )
            # 3. æ£€æŸ¥æŒä»“è®°å½•
            trades = portfolio.positions.records_readable
            expected_trades = improved_entries.sum().sum()
            logger.info(f"  æœŸæœ›äº¤æ˜“æ•°: {expected_trades}")
            logger.info(f"  å®é™…äº¤æ˜“æ•°: {len(trades)}")
            print(portfolio.stats())

            self.create_final_report(portfolio, holding_signals, 0, len(holding_signals)-1)
            self.plot_cumulative_returns_curve(portfolio)
            records = portfolio.trades.records_readable
            records
            self.portfolios[factor_name] = portfolio

        logger.info(f"ğŸ‰ {factor_dict.keys()}å› å­å›æµ‹å®Œæˆ")

        return self.portfolios

    def _generate_signals_final_version(
            self,
            holding_signals: pd.DataFrame,
            price_df: pd.DataFrame,
            max_holding_days: int = None,
            retry_buy_limit: int = 3
    ) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """
        ã€V7 - çŠ¶æ€æœºå¾ªç¯æœ€ç»ˆç‰ˆ - å®Œæ•´ä»£ç ã€‘
        - å¼•å…¥ actual_holdings çŠ¶æ€å˜é‡ï¼Œç²¾ç¡®è¿½è¸ªæ¯æ—¥çœŸå®æŒä»“ã€‚
        - æ–°å¢â€œå¾…ä¹°æ¸…å•â€é€»è¾‘ï¼Œå¤„ç†å› åœç‰Œæˆ–èµ„é‡‘ä¸è¶³è€Œå¤±è´¥çš„ä¹°å…¥ä¿¡å·ï¼Œå¹¶è®¾æœ‰â€œæœ‰æ•ˆæœŸâ€ã€‚
        - å½»åº•è§£å†³â€œè´Ÿæ•°æŒä»“â€ã€â€œåƒµå°¸ä¿¡å·â€ã€â€œå›å£°ä¿¡å·â€ç­‰æ‰€æœ‰çŠ¶æ€ç®¡ç†Bugã€‚
        - è¿™æ˜¯åœ¨ for å¾ªç¯æ¡†æ¶å†…æœ€ç¨³å¥çš„å®ç°ã€‚

        Args:
            holding_signals: â€œç†æƒ³æŒä»“è®¡åˆ’â€çŸ©é˜µ (æ¥è‡ªä¸Šæ¸¸å‡½æ•°)ã€‚
            price_df: å¯¹é½åçš„ä»·æ ¼æ•°æ®ã€‚
            max_holding_days: æœ€å¤§æŒä»“å¤©æ•°ï¼Œç”¨äºæ—¶é—´æ­¢æŸã€‚
            retry_buy_limit: ä¹°å…¥ä¿¡å·å¤±è´¥åï¼Œé‡è¯•çš„æœ€å¤§å¤©æ•°ã€‚

        Returns:
            Tuple[pd.DataFrame, pd.DataFrame]: (æœ€ç»ˆçš„ä¹°å…¥ä¿¡å·, æœ€ç»ˆçš„å–å‡ºä¿¡å·)
        """
        logger.info(f"ã€V7 æœ€ç»ˆç‰ˆã€‘å¼€å§‹ç”Ÿæˆä¿¡å·ï¼Œæœ€å¤§æŒä»“: {max_holding_days}, ä¹°å…¥é‡è¯•æœŸ: {retry_buy_limit}å¤©")

        # --- åˆå§‹åŒ– ---
        entries = pd.DataFrame(False, index=holding_signals.index, columns=holding_signals.columns)
        exits = pd.DataFrame(False, index=holding_signals.index, columns=holding_signals.columns)

        # --- çŠ¶æ€å˜é‡ ---
        # ã€æ ¸å¿ƒã€‘â€œå®é™…æŒä»“â€çŠ¶æ€ï¼Œä½œä¸ºå¾ªç¯å†…éƒ¨çš„åœ°é¢å®å†µ
        actual_holdings = pd.Series(False, index=holding_signals.columns)

        # æŒä»“å¤©æ•°è®¡æ•°å™¨
        holding_days = pd.Series(0, index=holding_signals.columns)

        # â€œå¾…å–æ¸…å•â€ï¼Œè¿½è¸ªéœ€è¦å–å‡ºä½†å¯èƒ½è¢«å»¶è¿Ÿçš„è‚¡ç¥¨
        pending_exits_tracker = pd.Series(False, index=holding_signals.columns)

        # â€œå¾…ä¹°æ¸…å•â€å’Œä»»åŠ¡æœ‰æ•ˆæœŸè®¡æ•°å™¨
        pending_buys_tracker = pd.Series(False, index=holding_signals.columns)
        pending_buys_age = pd.Series(0, index=holding_signals.columns)

        # --- é€æ—¥å¾ªç¯ç”Ÿæˆä¿¡å· ---
        for i in range(len(holding_signals)):
            curr_date = holding_signals.index[i]
            curr_holdings_plan = holding_signals.iloc[i]

            # --- 1. çŠ¶æ€æ›´æ–°ï¼ˆæ¯æ—¥å¼€å§‹æ—¶ï¼‰---
            # a. å¯¹â€œå¾…ä¹°æ¸…å•â€ä¸Šçš„ä»»åŠ¡è¿›è¡Œâ€œè€åŒ–â€ï¼Œå¹¶ä½œåºŸâ€œè¿‡æœŸâ€ä»»åŠ¡
            if pending_buys_tracker.any():
                pending_buys_age[pending_buys_tracker] += 1
                expired_buys = pending_buys_age > retry_buy_limit
                pending_buys_tracker[expired_buys] = False
                pending_buys_age[expired_buys] = 0

            # b. æ›´æ–°æŒä»“å¤©æ•°: åªä¸ºå®é™…æŒæœ‰çš„è‚¡ç¥¨ç´¯åŠ å¤©æ•°
            holding_days[actual_holdings] += 1

            # --- 2. ã€æ”¶é›†æ„å›¾ã€‘è®¡ç®—æ‰€æœ‰å¯èƒ½çš„â€œå–å‡ºæ„å›¾â€ ---
            # a. æ­£å¸¸è°ƒä»“å–å‡º: è®¡åˆ’ä¸å†æŒæœ‰ï¼Œä½†æˆ‘ä»¬å®é™…è¿˜æŒæœ‰
            normal_exits_intent = ~curr_holdings_plan & actual_holdings

            # b. å¼ºåˆ¶æŒæœ‰æœŸæ»¡å–å‡º: è¾¾åˆ°æœ€å¤§å¤©æ•°ä¸”ä»åœ¨å®é™…æŒæœ‰
            force_exit_intent = pd.Series(False, index=holding_signals.columns)
            if max_holding_days is not None:
                force_exit_intent = (holding_days >= max_holding_days) & actual_holdings

            # c. åˆå¹¶æ‰€æœ‰å–å‡ºæ„å›¾ï¼ˆåŒ…æ‹¬æ˜¨æ—¥æœªå®Œæˆçš„ï¼‰
            total_intent_to_sell = normal_exits_intent | force_exit_intent | pending_exits_tracker

            # --- 3. ã€æ”¶é›†æ„å›¾ã€‘è®¡ç®—æ‰€æœ‰å¯èƒ½çš„â€œä¹°å…¥æ„å›¾â€ ---
            # a. ä»Šå¤©æ–°äº§ç”Ÿçš„ä¹°å…¥æ„å›¾: è®¡åˆ’è¦æŒæœ‰ï¼Œä½†æˆ‘ä»¬å®é™…æ²¡æœ‰æŒæœ‰
            new_buy_intent = curr_holdings_plan & ~actual_holdings

            # b. åˆå¹¶â€œå¾…ä¹°æ¸…å•â€ä¸­çš„ä»»åŠ¡ï¼Œå½¢æˆâ€œä»Šæ—¥æ€»ä¹°å…¥æ„å›¾â€
            total_intent_to_buy = new_buy_intent | pending_buys_tracker

            # --- 4.ã€å¤„ç†æ‰§è¡Œã€‘ç»“åˆå¸‚åœºç°å®ï¼ˆåœç‰Œï¼‰ï¼Œå†³å®šä»Šå¤©å®é™…çš„äº¤æ˜“ ---
            is_tradable_today = price_df.iloc[i].notna()

            executable_exits = total_intent_to_sell & is_tradable_today
            executable_entries = total_intent_to_buy & is_tradable_today

            # è®°å½•æœ€ç»ˆä¿¡å·
            exits.iloc[i] = executable_exits
            entries.iloc[i] = executable_entries

            # --- 5.ã€æ›´æ–°çŠ¶æ€ã€‘ä¸ºâ€œæ˜å¤©â€å‡†å¤‡å¥½æ‰€æœ‰çŠ¶æ€å˜é‡ ---
            # a. æ›´æ–°â€œå®é™…æŒä»“â€
            actual_holdings = (actual_holdings | executable_entries) & ~executable_exits

            # b. æ›´æ–°â€œå¾…å–æ¸…å•â€
            pending_exits_tracker = total_intent_to_sell & ~is_tradable_today

            # c. æ›´æ–°â€œå¾…ä¹°æ¸…å•â€å’Œâ€œå¹´é¾„â€
            pending_buys_tracker = total_intent_to_buy & ~executable_entries
            pending_buys_age[~pending_buys_tracker] = 0  # ä¸åœ¨æ¸…å•ä¸Šçš„ï¼Œå¹´é¾„å½’é›¶
            # æ–°åŠ å…¥æ¸…å•çš„ï¼Œå¹´é¾„ä»1å¼€å§‹ï¼ˆå› ä¸ºä»Šå¤©å·²ç»ç®—ä¸€å¤©äº†ï¼‰
            newly_pending_buys_mask = pending_buys_tracker & (pending_buys_age == 0)
            pending_buys_age[newly_pending_buys_mask] = 1

            # d. æ›´æ–°â€œæŒä»“å¤©æ•°â€
            # å¯¹äºä»Šå¤©æ–°ä¹°å…¥çš„ï¼Œå¤©æ•°è®¾ä¸º1ï¼›å¯¹äºä»Šå¤©å–å‡ºçš„ï¼Œå¤©æ•°å½’é›¶
            holding_days[executable_entries] = 1
            holding_days[executable_exits] = 0

        # --- æœŸæœ«å¤„ç† ---
        # åœ¨æœ€åä¸€ä¸ªäº¤æ˜“æ—¥ï¼Œå¼ºåˆ¶æ¸…ä»“æ‰€æœ‰ä»åœ¨æŒæœ‰çš„ã€æˆ–ä»åœ¨å¾…å–æ¸…å•ä¸Šçš„è‚¡ç¥¨
        final_holdings = actual_holdings | pending_exits_tracker
        is_tradable_last_day = price_df.iloc[-1].notna()
        exits.iloc[-1] = exits.iloc[-1] | (final_holdings & is_tradable_last_day)

        logger.info(f"ä¿¡å·ç”Ÿæˆå®Œæˆ: ä¹°å…¥ä¿¡å·({entries.sum().sum()})ä¸ª, æ€»å–å‡ºä¿¡å·({exits.sum().sum()})ä¸ª")
        return entries, exits

    def generate_wide_format_orders(
            self,
            holding_signals: pd.DataFrame,
            price_df: pd.DataFrame,
            init_cash: float,
            fees: float,
            max_holding_days: int = None,
            retry_buy_limit: int = 3
    ) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
        """
        ã€V9 - å®½æ ¼å¼è®¢å•ç”Ÿæˆå™¨ã€‘
        - åœ¨å¾ªç¯å†…å®Œæ•´æ¨¡æ‹Ÿç°é‡‘ã€æŒä»“è‚¡æ•°ç­‰çŠ¶æ€ã€‚
        - ç›´æ¥ç”Ÿæˆ from_orders æ‰€éœ€çš„ size, price, direction ä¸‰ä¸ªå®½æ ¼å¼DataFrameã€‚
        - è¿™æ˜¯åœ¨æœ€åº•å±‚æ¥å£ä¸Šå·¥ä½œçš„ç»ˆæè§£å†³æ–¹æ¡ˆã€‚
        """
        logger.info(f"ã€V9 å®½æ ¼å¼è®¢å•ç”Ÿæˆå™¨ç‰ˆã€‘å¼€å§‹ç”Ÿæˆç²¾ç¡®è®¢å•...")

        # --- åˆå§‹åŒ– ---
        # ä¸º size, price, direction åˆ›å»ºç©ºçš„ã€ä¸ä»·æ ¼è¡¨å¯¹é½çš„DataFrame
        # ç”¨ np.nan å¡«å……ï¼Œå› ä¸º0å¯èƒ½æ˜¯ä¸€ä¸ªæœ‰æ•ˆå€¼ï¼ˆæ¯”å¦‚size=0ï¼‰
        size_df = pd.DataFrame(np.nan, index=holding_signals.index, columns=holding_signals.columns)
        price_df_orders = pd.DataFrame(np.nan, index=holding_signals.index, columns=holding_signals.columns)
        direction_df = pd.DataFrame(np.nan, index=holding_signals.index, columns=holding_signals.columns)

        # --- çŠ¶æ€å˜é‡ (ä¸V8ç›¸åŒ) ---
        cash = init_cash
        actual_positions = pd.Series(0, index=holding_signals.columns)
        # ... (å…¶ä»–çŠ¶æ€å˜é‡ï¼šholding_days, pending_exits, pending_buys, pending_buys_age)
        holding_days = pd.Series(0, index=holding_signals.columns)
        pending_exits_tracker = pd.Series(False, index=holding_signals.columns)
        pending_buys_tracker = pd.Series(False, index=holding_signals.columns)
        pending_buys_age = pd.Series(0, index=holding_signals.columns)

        # --- é€æ—¥å¾ªç¯ï¼Œæ¨¡æ‹Ÿäº¤æ˜“ ---
        for i in range(len(holding_signals)):
            curr_date = holding_signals.index[i]
            # ... (æ‰€æœ‰V8ç‰ˆæœ¬çš„çŠ¶æ€æ›´æ–°å’Œæ„å›¾æ”¶é›†é€»è¾‘å®Œå…¨ä¸å˜) ...
            # --- Start of copy from V8.1 logic ---
            if pending_buys_tracker.any():
                pending_buys_age[pending_buys_tracker] += 1
                expired_buys = pending_buys_age > retry_buy_limit
                pending_buys_tracker[expired_buys] = False
                pending_buys_age[expired_buys] = 0
            currently_held_mask = actual_positions > 0
            holding_days[currently_held_mask] += 1
            curr_holdings_plan = holding_signals.iloc[i]
            normal_exits_intent = ~curr_holdings_plan & currently_held_mask
            force_exit_intent = pd.Series(False, index=holding_signals.columns)
            if max_holding_days is not None:
                force_exit_intent = (holding_days >= max_holding_days) & currently_held_mask
            total_intent_to_sell = normal_exits_intent | force_exit_intent | pending_exits_tracker
            new_buy_intent = curr_holdings_plan & ~currently_held_mask
            total_intent_to_buy = new_buy_intent | pending_buys_tracker
            is_tradable_today = price_df.iloc[i].notna()
            executable_exits_mask = total_intent_to_sell & is_tradable_today
            executable_entries_mask = total_intent_to_buy & is_tradable_today
            # --- End of copy from V8.1 logic ---

            # --- ã€æ ¸å¿ƒæ”¹é€ ã€‘ç›´æ¥å¡«å……å®½æ ¼å¼DataFrameï¼Œè€Œä¸æ˜¯appendåˆ°list ---

            # a. å¤„ç†å–å‡º
            stocks_to_sell = executable_exits_mask[executable_exits_mask].index
            for stock in stocks_to_sell:
                price = price_df.loc[curr_date, stock]
                size_to_sell = actual_positions[stock]
                if size_to_sell > 0:
                    size_df.loc[curr_date, stock] = size_to_sell
                    price_df_orders.loc[curr_date, stock] = price
                    direction_df.loc[curr_date, stock] = 1  # 1 for Sell
                    cash += size_to_sell * price * (1 - fees)
                    actual_positions[stock] = 0

            # b. å¤„ç†ä¹°å…¥
            stocks_to_buy = executable_entries_mask[executable_entries_mask].index
            num_buys = len(stocks_to_buy)
            if num_buys > 0:
                cash_per_stock = cash / num_buys
                for stock in stocks_to_buy:
                    price = price_df.loc[curr_date, stock]
                    if price > 0:
                        size_to_buy = np.floor((cash_per_stock / (price * (1 + fees))) / 100) * 100
                        if size_to_buy > 0:
                            size_df.loc[curr_date, stock] = size_to_buy
                            price_df_orders.loc[curr_date, stock] = price
                            direction_df.loc[curr_date, stock] = -1  # 0 for Buy
                            cash -= size_to_buy * price * (1 + fees)
                            actual_positions[stock] += size_to_buy

            # ... (æ‰€æœ‰V8ç‰ˆæœ¬çš„çŠ¶æ€æ›´æ–°é€»è¾‘å®Œå…¨ä¸å˜) ...
            # --- Start of copy from V8.1 logic for state update ---
            executed_entries_today = pd.Series(False, index=holding_signals.columns)
            for stock in stocks_to_buy:  # More robust check for executed entries
                if size_df.loc[curr_date, stock] > 0:
                    executed_entries_today[stock] = True
            pending_exits_tracker = total_intent_to_sell & ~is_tradable_today
            pending_buys_tracker = total_intent_to_buy & ~executed_entries_today
            pending_buys_age[~pending_buys_tracker] = 0
            newly_pending_buys_mask = pending_buys_tracker & (pending_buys_age == 0)
            pending_buys_age[newly_pending_buys_mask] = 1
            holding_days[executed_entries_today] = 1
            holding_days[executable_exits_mask] = 0
            # --- End of copy from V8.1 logic for state update ---

        return size_df, price_df_orders, direction_df
    #from_order
    def run_backtest(
            self,
            price_df: pd.DataFrame,
            factor_dict: Dict[str, pd.DataFrame]
    ) -> Dict[str, any]:
        # 1. æ•°æ®å‡†å¤‡
        all_dfs = [price_df] + list(factor_dict.values())
        aligned_dfs = vbt.base.reshape_fns.broadcast(*all_dfs, keep_pd=True, align_index=True, align_columns=True)

        aligned_price = aligned_dfs[0]
        aligned_factors = {name: df for name, df in zip(factor_dict.keys(), aligned_dfs[1:])}
        logger.info(f"æ•°æ®å¯¹é½å®Œæˆï¼Œæœ€ç»ˆç»´åº¦: {aligned_price.shape}")
        # 2. é€ä¸ªå› å­å›æµ‹
        for factor_name, factor_data in aligned_factors.items():
            logger.info(f"ğŸš€ å¼€å§‹å›æµ‹å› å­: {factor_name}")
            # 3. ä¿¡å·ç”Ÿæˆæµæ°´çº¿
            # é¦–å…ˆï¼Œç”Ÿæˆæ¯æ—¥çš„ç›®æ ‡æŒä»“çŠ¶æ€ å…¨æ˜¯true false è¡¨ç¤ºå½“æ—¥rankæƒ…å†µçš„true flase
            holding_signals = self.signal_generator.generate_long_holding_signals(factor_data, aligned_price,
                                                                                  self.config)

            origin_weights_df = self.get_position_weights_by_per_weight(holding_signals)
            self.myself_debug_data(origin_weights_df)
            # ç…§é¡¾vector ä¸“é—¨ä¸ºä»–ç®—æœ¯ï¼
            weights_df = convert_to_sequential_percents(origin_weights_df)
            # è®¡ç®—åˆç†çš„ç»¼åˆäº¤æ˜“è´¹ç”¨
            # ä¹°å…¥æˆæœ¬: ä½£é‡‘(ä¸‡3) + æ»‘ç‚¹(åƒ1) = 0.0003 + 0.001 = 0.0013
            # å–å‡ºæˆæœ¬: ä½£é‡‘(ä¸‡3) + å°èŠ±ç¨(åƒ1) + æ»‘ç‚¹(åƒ1) = 0.0003 + 0.001 + 0.001 = 0.0023
            # å¹³å‡åŒè¾¹æˆæœ¬: (0.0013 + 0.0023) / 2 = 0.0018
            comprehensive_fee_rate = (
                    self.config.commission_rate +  # ä½£é‡‘ 0.0003
                    self.config.slippage_rate +  # æ»‘ç‚¹ 0.001
                    self.config.stamp_duty / 2  # å°èŠ±ç¨åˆ†æ‘Š 0.0005
            )
            # æ”¹è¿›é€€å‡ºä¿¡å·ç”Ÿæˆ - ç¡®ä¿åœ¨æ—¶é—´çª—å£ç»“æŸæ—¶å¼ºåˆ¶é€€å‡º (è¿™æ ·åšï¼Œåªæ˜¯ä¸ºäº†ç®€å•ç›´è§‚çœ‹å‡ºæˆ‘çš„ç­–ç•¥æ•ˆæœï¼
            improved_entries, improved_exits = self._generate_improved_signals(
                holding_signals, aligned_price, max_holding_days=self.config.max_holding_days
            )
            # ã€æ–°å¢è°ƒè¯•ã€‘æ£€æŸ¥ä¿¡å·çš„è¯¦ç»†æƒ…å†µ
            self.debug_signal_generation(holding_signals, self.config, improved_entries, improved_exits,
                                         origin_weights_df, 0, len(holding_signals) - 1)

            # 1. æ£€æŸ¥å®é™…çš„äº¤æ˜“è®°å½•

            # 2. ã€æ ¸å¿ƒã€‘è°ƒç”¨V9è®¢å•ç”Ÿæˆå™¨ï¼Œè·å–ä¸‰ä»½â€œé…æ–™è¡¨â€
            size_wide_df, price_wide_df, direction_wide_df = self.generate_wide_format_orders(
                holding_signals=holding_signals,
                price_df=aligned_price,
                init_cash=self.config.initial_cash,
                fees=comprehensive_fee_rate,
                max_holding_days=60
                # ... å…¶ä»–å‚æ•° ...
            )

            # 3. å°†è¿™ä¸‰ä»½ç²¾ç¡®çš„â€œé…æ–™è¡¨â€äº¤ç»™ vectorbt çš„åº•å±‚å¨å¸ˆ
            portfolio = vbt.Portfolio.from_orders(
                close=aligned_price,
                size=size_wide_df,
                price=price_wide_df,
                direction=direction_wide_df,

                # æˆ‘ä»¬ä¸å†éœ€è¦ä»»ä½• sizing æˆ– signal å‚æ•°

                init_cash=self.config.initial_cash,
                fees=0,  # å› ä¸ºæˆ‘ä»¬å·²åœ¨å¾ªç¯ä¸­æ‰‹åŠ¨è®¡ç®—äº†è´¹ç”¨
                freq='D'
            )


            # 3. æ£€æŸ¥æŒä»“è®°å½•
            trades = portfolio.positions.records_readable
            expected_trades = improved_entries.sum().sum()
            logger.info(f"  æœŸæœ›äº¤æ˜“æ•°: {expected_trades}")
            logger.info(f"  å®é™…äº¤æ˜“æ•°: {len(trades)}")
            print(portfolio.stats())

            self.create_final_report(portfolio, holding_signals, 0, len(holding_signals) - 1)
            self.plot_cumulative_returns_curve(portfolio)
            records = portfolio.trades.records_readable
            records
            self.portfolios[factor_name] = portfolio

        logger.info(f"ğŸ‰ {factor_dict.keys()}å› å­å›æµ‹å®Œæˆ")

        return self.portfolios

    def generate_orders_final_version(
            self,
            holding_signals: pd.DataFrame,
            price_df: pd.DataFrame,
            init_cash: float,
            fees: float,
            max_holding_days: int = None,
            retry_buy_limit: int = 3
    ) -> pd.DataFrame:
        """
        ã€V8.1 - è®¢å•ç”Ÿæˆå™¨æœ€ç»ˆç‰ˆ - å®Œæ•´ä»£ç ã€‘
        - åœ¨å¾ªç¯å†…å®Œæ•´æ¨¡æ‹Ÿç°é‡‘ã€æŒä»“è‚¡æ•°ç­‰æ‰€æœ‰çŠ¶æ€ã€‚
        - ç”Ÿæˆç²¾ç¡®çš„ä¹°å–è®¢å•åˆ—è¡¨ï¼Œä¾› Portfolio.from_orders ä½¿ç”¨ã€‚
        - è¡¥å…¨äº†æ‰€æœ‰çŠ¶æ€æ›´æ–°é€»è¾‘ï¼Œç¡®ä¿è¡Œä¸ºçš„ç²¾ç¡®æ€§ã€‚
        - è¿™æ˜¯åœ¨æ— æ³•ä½¿ç”¨ target-based sizing æ¨¡å¼ä¸‹çš„ç»ˆæè§£å†³æ–¹æ¡ˆã€‚
        """
        logger.info(f"ã€V8.1 è®¢å•ç”Ÿæˆå™¨ç‰ˆã€‘å¼€å§‹ç”Ÿæˆç²¾ç¡®è®¢å•...")

        # --- åˆå§‹åŒ– ---
        order_records = []

        # --- çŠ¶æ€å˜é‡ ---
        cash = init_cash
        actual_positions = pd.Series(0, index=holding_signals.columns)  # è¿½è¸ªæŒä»“è‚¡æ•°
        holding_days = pd.Series(0, index=holding_signals.columns)
        pending_exits_tracker = pd.Series(False, index=holding_signals.columns)
        pending_buys_tracker = pd.Series(False, index=holding_signals.columns)
        pending_buys_age = pd.Series(0, index=holding_signals.columns)

        # --- é€æ—¥å¾ªç¯ï¼Œæ¨¡æ‹Ÿäº¤æ˜“ ---
        for i in range(len(holding_signals)):
            curr_date = holding_signals.index[i]
            curr_holdings_plan = holding_signals.iloc[i]

            # --- 1. çŠ¶æ€æ›´æ–°ï¼ˆæ¯æ—¥å¼€å§‹æ—¶ï¼‰ ---
            if pending_buys_tracker.any():
                pending_buys_age[pending_buys_tracker] += 1
                expired_buys = pending_buys_age > retry_buy_limit
                pending_buys_tracker[expired_buys] = False
                pending_buys_age[expired_buys] = 0

            currently_held_mask = actual_positions > 0
            holding_days[currently_held_mask] += 1

            # --- 2. ã€æ”¶é›†æ„å›¾ã€‘ ---
            normal_exits_intent = ~curr_holdings_plan & currently_held_mask
            force_exit_intent = pd.Series(False, index=holding_signals.columns)
            if max_holding_days is not None:
                force_exit_intent = (holding_days >= max_holding_days) & currently_held_mask

            total_intent_to_sell = normal_exits_intent | force_exit_intent | pending_exits_tracker
            new_buy_intent = curr_holdings_plan & ~currently_held_mask
            total_intent_to_buy = new_buy_intent | pending_buys_tracker

            # --- 3.ã€å¤„ç†æ‰§è¡Œã€‘---
            is_tradable_today = price_df.iloc[i].notna()
            executable_exits_mask = total_intent_to_sell & is_tradable_today
            executable_entries_mask = total_intent_to_buy & is_tradable_today

            # --- 4.ã€ç”Ÿæˆç²¾ç¡®è®¢å•ã€‘---
            executed_entries_today = pd.Series(False, index=holding_signals.columns)  # ç²¾ç¡®è®°å½•å½“æ—¥æˆåŠŸä¹°å…¥

            # a. å¤„ç†å–å‡ºè®¢å• (Sell Phase)
            stocks_to_sell = executable_exits_mask[executable_exits_mask].index
            for stock in stocks_to_sell:
                price = price_df.loc[curr_date, stock]
                size_to_sell = actual_positions[stock]
                if size_to_sell > 0:
                    order_records.append({
                        'Timestamp': curr_date, 'Symbol': stock, 'Size': size_to_sell,
                        'Side': 1, 'Price': price
                    })
                    cash += size_to_sell * price * (1 - fees)
                    actual_positions[stock] = 0

            # b. å¤„ç†ä¹°å…¥è®¢å• (Buy Phase)
            stocks_to_buy = executable_entries_mask[executable_entries_mask].index
            num_buys = len(stocks_to_buy)
            if num_buys > 0:
                cash_per_stock = cash / num_buys

                for stock in stocks_to_buy:
                    price = price_df.loc[curr_date, stock]
                    if price > 0:
                        size_to_buy = (cash_per_stock / (price * (1 + fees)))
                        size_to_buy = np.floor(size_to_buy / 100) * 100

                        if size_to_buy > 0:
                            order_records.append({
                                'Timestamp': curr_date, 'Symbol': stock, 'Size': size_to_buy,
                                'Side': 0, 'Price': price
                            })
                            cash -= size_to_buy * price * (1 + fees)
                            actual_positions[stock] += size_to_buy
                            executed_entries_today[stock] = True  # ç²¾ç¡®æ ‡è®°æˆåŠŸä¹°å…¥

            # --- 5.ã€æ›´æ–°çŠ¶æ€ã€‘ä¸ºâ€œæ˜å¤©â€å‡†å¤‡ ---
            # a. å¾…å–æ¸…å•: å–å‡ºæ„å›¾å­˜åœ¨ï¼Œä½†ä»Šå¤©æ— æ³•äº¤æ˜“
            pending_exits_tracker = total_intent_to_sell & ~is_tradable_today

            # b. å¾…ä¹°æ¸…å•: ä¹°å…¥æ„å›¾å­˜åœ¨ï¼Œä½†ä»Šå¤©æœªæˆåŠŸæ‰§è¡Œ
            pending_buys_tracker = total_intent_to_buy & ~executed_entries_today

            # c. å¾…ä¹°æ¸…å•å¹´é¾„
            pending_buys_age[~pending_buys_tracker] = 0
            newly_pending_buys_mask = pending_buys_tracker & (pending_buys_age == 0)
            pending_buys_age[newly_pending_buys_mask] = 1

            # d. æŒä»“å¤©æ•°
            holding_days[executed_entries_today] = 1  # æ–°ä¹°å…¥çš„ï¼Œå¤©æ•°è®¾ä¸º1
            holding_days[executable_exits_mask] = 0  # æˆåŠŸå–å‡ºçš„ï¼Œå¤©æ•°å½’é›¶

        # --- æœŸæœ«å¤„ç†ä¸è¿”å› ---
        if not order_records:
            return pd.DataFrame(columns=['Timestamp', 'Symbol', 'Size', 'Side', 'Price'])

        # å°†è®¢å•åˆ—è¡¨è½¬æ¢ä¸º vectorbt éœ€è¦çš„æ ¼å¼
        order_df = pd.DataFrame(order_records)
        order_df = order_df.rename(
            columns={'Timestamp': 'Order Timestamp', 'Symbol': 'Symbol', 'Size': 'Size', 'Side': 'Side', 'Price': 'Price'})
        order_df = order_df.set_index('Order Timestamp')

        return order_df

    def run_backtest_from_order(
            self,
            price_df: pd.DataFrame,
            factor_dict: Dict[str, pd.DataFrame]
    ) -> Dict[str, any]:
        # 1. æ•°æ®å‡†å¤‡
        all_dfs = [price_df] + list(factor_dict.values())
        aligned_dfs = vbt.base.reshape_fns.broadcast(*all_dfs, keep_pd=True, align_index=True, align_columns=True)

        aligned_price = aligned_dfs[0]
        aligned_factors = {name: df for name, df in zip(factor_dict.keys(), aligned_dfs[1:])}
        logger.info(f"æ•°æ®å¯¹é½å®Œæˆï¼Œæœ€ç»ˆç»´åº¦: {aligned_price.shape}")
        # 2. é€ä¸ªå› å­å›æµ‹
        for factor_name, factor_data in aligned_factors.items():
            logger.info(f"ğŸš€ å¼€å§‹å›æµ‹å› å­: {factor_name}")
            # 3. ä¿¡å·ç”Ÿæˆæµæ°´çº¿
            # é¦–å…ˆï¼Œç”Ÿæˆæ¯æ—¥çš„ç›®æ ‡æŒä»“çŠ¶æ€ å…¨æ˜¯true false è¡¨ç¤ºå½“æ—¥rankæƒ…å†µçš„true flase
            holding_signals = self.signal_generator.generate_long_holding_signals(factor_data, aligned_price,
                                                                                  self.config)

            origin_weights_df = self.get_position_weights_by_per_weight(holding_signals)
            self.myself_debug_data(origin_weights_df)
            #ç…§é¡¾vector ä¸“é—¨ä¸ºä»–ç®—æœ¯ï¼
            weights_df = convert_to_sequential_percents(origin_weights_df)
            # è®¡ç®—åˆç†çš„ç»¼åˆäº¤æ˜“è´¹ç”¨
            # ä¹°å…¥æˆæœ¬: ä½£é‡‘(ä¸‡3) + æ»‘ç‚¹(åƒ1) = 0.0003 + 0.001 = 0.0013
            # å–å‡ºæˆæœ¬: ä½£é‡‘(ä¸‡3) + å°èŠ±ç¨(åƒ1) + æ»‘ç‚¹(åƒ1) = 0.0003 + 0.001 + 0.001 = 0.0023
            # å¹³å‡åŒè¾¹æˆæœ¬: (0.0013 + 0.0023) / 2 = 0.0018
            comprehensive_fee_rate = (
                    self.config.commission_rate +  # ä½£é‡‘ 0.0003
                    self.config.slippage_rate +  # æ»‘ç‚¹ 0.001
                    self.config.stamp_duty / 2  # å°èŠ±ç¨åˆ†æ‘Š 0.0005
            )
            # æ”¹è¿›é€€å‡ºä¿¡å·ç”Ÿæˆ - ç¡®ä¿åœ¨æ—¶é—´çª—å£ç»“æŸæ—¶å¼ºåˆ¶é€€å‡º (è¿™æ ·åšï¼Œåªæ˜¯ä¸ºäº†ç®€å•ç›´è§‚çœ‹å‡ºæˆ‘çš„ç­–ç•¥æ•ˆæœï¼
            improved_entries, improved_exits = self._generate_improved_signals(
                holding_signals, aligned_price, max_holding_days=self.config.max_holding_days
            )
            # ã€æ–°å¢è°ƒè¯•ã€‘æ£€æŸ¥ä¿¡å·çš„è¯¦ç»†æƒ…å†µ
            self.debug_signal_generation(holding_signals, self.config, improved_entries, improved_exits, origin_weights_df,0,len(holding_signals)-1)



    def get_daily_holdings_count_from_trades(self,portfolio, full_date_index: pd.DatetimeIndex) -> pd.Series:
        """
        ã€é€šç”¨ç‰ˆã€‘ä»æœ€åº•å±‚çš„äº¤æ˜“è®°å½•ä¸­ï¼Œç²¾ç¡®é‡æ„æ¯æ—¥çš„å®é™…æŒä»“è‚¡ç¥¨æ•°é‡ã€‚
        ä¸ä¾èµ–ä»»ä½•é«˜ç‰ˆæœ¬ vectorbt çš„ç‰¹å®šå±æ€§ã€‚

        Args:
            portfolio: vectorbt å›æµ‹å®Œæˆåè¿”å›çš„ Portfolio å¯¹è±¡ã€‚
            full_date_index: å®Œæ•´çš„ã€åŒ…å«æ‰€æœ‰å›æµ‹æ—¥æœŸçš„ç´¢å¼•ã€‚

        Returns:
            pd.Series: ç´¢å¼•ä¸ºæ—¥æœŸï¼Œå€¼ä¸ºå½“å¤©å®é™…æŒä»“è‚¡ç¥¨æ•°çš„åºåˆ—ã€‚
        """
        trades = portfolio.trades.records_readable

        if trades.empty:
            # å¦‚æœæ²¡æœ‰ä»»ä½•äº¤æ˜“ï¼Œåˆ™å§‹ç»ˆæŒä»“ä¸º0
            return pd.Series(0, index=full_date_index)

        # 1. è·å–æ‰€æœ‰â€œå…¥åœºâ€äº‹ä»¶ï¼ŒæŒ‰å¤©ç»Ÿè®¡
        entry_events = trades.groupby(trades['Entry Timestamp'].dt.date).size()
        entry_events.name = 'entries'

        # 2. è·å–æ‰€æœ‰â€œå‡ºåœºâ€äº‹ä»¶ï¼ŒæŒ‰å¤©ç»Ÿè®¡
        exit_events = trades.groupby(trades['Exit Timestamp'].dt.date).size()
        exit_events.name = 'exits'

        # 3. å°†äº‹ä»¶åˆå¹¶ï¼Œè®¡ç®—æ¯æ—¥çš„â€œå‡€æŒä»“å˜åŒ–â€
        #   æ³¨æ„ .dt.date ä¼šå¯¼è‡´ç´¢å¼•å˜ä¸º objectï¼Œéœ€è¦è½¬å› datetime
        entry_events.index = pd.to_datetime(entry_events.index)
        exit_events.index = pd.to_datetime(exit_events.index)

        daily_net_change = entry_events.sub(exit_events, fill_value=0)

        # 4. å°†â€œå‡€å˜åŒ–â€æ‰©å±•åˆ°æ•´ä¸ªå›æµ‹å‘¨æœŸ
        #   åœ¨æ²¡æœ‰äº¤æ˜“çš„æ—¥å­é‡Œï¼Œå‡€å˜åŒ–ä¸º0
        daily_net_change_full = daily_net_change.reindex(full_date_index, fill_value=0)

        # 5. ã€æ ¸å¿ƒã€‘å¯¹æ¯æ—¥çš„å‡€å˜åŒ–è¿›è¡Œç´¯ç§¯æ±‚å’Œï¼Œå¾—åˆ°æ¯æ—¥çš„æœ€ç»ˆæŒä»“æ•°
        actual_positions_count = daily_net_change_full.cumsum().astype(int)

        return actual_positions_count
    def create_final_report(
            self,
            portfolio,
            holding_signals: pd.DataFrame,
            sidx: int,
            eidx: int
    ):
        """
        ã€æ³•åŠ¡å®¡è®¡çº§ V3.1 - å…¼å®¹ç‰ˆã€‘
        - ä½¿ç”¨ä»äº¤æ˜“è®°å½•ä¸­é‡æ„çš„æ¯æ—¥æŒä»“æ•°ï¼Œå…¼å®¹æ—§ç‰ˆ vectorbtã€‚
        """
        logger.info("ğŸ”ã€æ³•åŠ¡å®¡è®¡çº§ V3.1 å…¼å®¹ç‰ˆã€‘æ—¥å¿—åˆ†æå¼€å§‹...")

        # --- 1. ä½¿ç”¨æˆ‘ä»¬æ–°çš„ã€å…¼å®¹æ€§å¼ºçš„å‡½æ•°æ¥è·å–â€œåœ°é¢å®å†µâ€ ---
        actual_holdings_count = self.get_daily_holdings_count_from_trades(
            portfolio=portfolio,
            full_date_index=holding_signals.index
        )

        # --- åç»­é€»è¾‘ä¸ä¹‹å‰å®Œå…¨ç›¸åŒ ---
        trades = portfolio.trades.records_readable
        daily_entries_count = trades.groupby(trades['Entry Timestamp'].dt.date).size()
        daily_exits_count = trades.groupby(trades['Exit Timestamp'].dt.date).size()

        log_df = pd.DataFrame(index=holding_signals.index)
        log_df['intended_holdings'] = holding_signals.sum(axis=1)
        log_df['actual_holdings'] = actual_holdings_count

        daily_entries_count.index = pd.to_datetime(daily_entries_count.index)
        daily_exits_count.index = pd.to_datetime(daily_exits_count.index)

        log_df['actual_entries'] = daily_entries_count
        log_df['actual_exits'] = daily_exits_count
        log_df = log_df.fillna(0).astype(int)

        # --- 3. æ‰“å°æ—¥å¿— ---
        sample_dates = log_df.index[sidx:eidx]
        for date in sample_dates:
            row = log_df.loc[date]
            log_msg = (
                f"{date.strftime('%Y-%m-%d')}: "
                f"å®é™…æŒä»“({row['actual_holdings']}), "
                f"å®é™…å–å‡º({row['actual_exits']}), "
                f"å®é™…ä¹°å…¥({row['actual_entries']})"
            )
            logger.info(log_msg)

        return log_df
    def _recalculate_trade_metric(self, corrected_stats, trades, metric):
        """é‡æ–°è®¡ç®—ç‰¹å®šçš„äº¤æ˜“æŒ‡æ ‡"""
        # ã€ä¿®å¤ã€‘æ­£ç¡®è¿‡æ»¤å·²å…³é—­äº¤æ˜“ - Statuså¯èƒ½æ˜¯å­—ç¬¦ä¸²'Closed'æˆ–æ•´æ•°1
        if 'Status' in trades.columns:
            status_values = trades['Status'].unique()
            if 'Closed' in status_values:
                closed_trades = trades[trades['Status'] == 'Closed']
            elif 1 in status_values:
                closed_trades = trades[trades['Status'] == 1]
            else:
                # å¦‚æœStatuså€¼æœªçŸ¥ï¼Œå‡è®¾æ‰€æœ‰äº¤æ˜“éƒ½å·²å…³é—­
                closed_trades = trades
        else:
            closed_trades = trades

        if len(closed_trades) > 0:
            winning_trades = closed_trades[closed_trades['PnL'] > 0]
            losing_trades = closed_trades[closed_trades['PnL'] < 0]

            if metric == 'Win Rate [%]':
                win_rate = len(winning_trades) / len(closed_trades) * 100
                corrected_stats[metric] = win_rate
            elif metric == 'Best Trade [%]':
                corrected_stats[metric] = closed_trades['Return'].max() * 100
            elif metric == 'Worst Trade [%]':
                corrected_stats[metric] = closed_trades['Return'].min() * 100
            elif metric == 'Avg Winning Trade [%]':
                if len(winning_trades) > 0:
                    corrected_stats[metric] = winning_trades['Return'].mean() * 100
                else:
                    corrected_stats[metric] = 0
            elif metric == 'Avg Losing Trade [%]':
                if len(losing_trades) > 0:
                    corrected_stats[metric] = losing_trades['Return'].mean() * 100
                else:
                    corrected_stats[metric] = 0
            elif metric == 'Expectancy':
                corrected_stats[metric] = closed_trades['PnL'].mean()
        else:
            corrected_stats[metric] = 0


    def get_comparison_table(self, metrics: Optional[List[str]] = None) -> pd.DataFrame:
        """
        ç”Ÿæˆå› å­å¯¹æ¯”è¡¨
        
        Args:
            metrics: è¦å¯¹æ¯”çš„æŒ‡æ ‡åˆ—è¡¨
            
        Returns:
            pd.DataFrame: å¯¹æ¯”ç»“æœè¡¨
        """
        if not self.portfolios:
            raise ValueError("è¯·å…ˆè¿è¡Œå›æµ‹")

        if metrics is None:
            metrics = [
                'Total Return [%]',
                'Sharpe Ratio',
                'Calmar Ratio',
                'Max Drawdown [%]',
                'Win Rate [%]',
                'Profit Factor'
            ]

        comparison_data = {}
        for factor_name, portfolio in self.portfolios.items():
            stats = portfolio.stats()
            comparison_data[factor_name] = stats[metrics]

        comparison_df = pd.DataFrame(comparison_data).T
        logger.info("å› å­å¯¹æ¯”è¡¨ç”Ÿæˆå®Œæˆ")
        return comparison_df

    def plot_cumulative_returns(self,
                                figsize: Tuple[int, int] = (15, 8),
                                save_path: Optional[str] = None) -> None:
        """
        ç»˜åˆ¶ç´¯ç§¯æ”¶ç›Šç‡æ›²çº¿
        
        Args:
            figsize: å›¾ç‰‡å¤§å°
            save_path: ä¿å­˜è·¯å¾„
        """
        if not self.portfolios:
            raise ValueError("è¯·å…ˆè¿è¡Œå›æµ‹")

        plt.figure(figsize=figsize)

        for factor_name, portfolio in self.portfolios.items():
            returns = portfolio.returns()
            cumulative_returns = (1 + returns).cumprod()
            plt.plot(cumulative_returns.index, cumulative_returns.values,
                     label=factor_name, linewidth=2)

        plt.title('å› å­ç­–ç•¥ç´¯ç§¯æ”¶ç›Šç‡å¯¹æ¯”', fontsize=16, fontweight='bold')
        plt.xlabel('æ—¥æœŸ', fontsize=12)
        plt.ylabel('ç´¯ç§¯æ”¶ç›Šç‡', fontsize=12)
        plt.legend(fontsize=11)
        plt.grid(True, alpha=0.3)
        plt.xticks(rotation=45)

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            logger.info(f"å›¾è¡¨å·²ä¿å­˜: {save_path}")

        plt.show()

    def plot_drawdown_analysis(self,
                               figsize: Tuple[int, int] = (15, 10),
                               save_path: Optional[str] = None) -> None:
        """
        ç»˜åˆ¶å›æ’¤åˆ†æå›¾
        
        Args:
            figsize: å›¾ç‰‡å¤§å°
            save_path: ä¿å­˜è·¯å¾„
        """
        if not self.portfolios:
            raise ValueError("è¯·å…ˆè¿è¡Œå›æµ‹")

        n_factors = len(self.portfolios)
        fig, axes = plt.subplots(n_factors, 1, figsize=figsize, sharex=True)
        if n_factors == 1:
            axes = [axes]

        for i, (factor_name, portfolio) in enumerate(self.portfolios.items()):
            drawdown = portfolio.drawdown()
            axes[i].fill_between(drawdown.index, drawdown.values, 0,
                                 color='red', alpha=0.3)
            axes[i].set_title(f'{factor_name} - å›æ’¤åˆ†æ', fontsize=14)
            axes[i].set_ylabel('å›æ’¤ (%)', fontsize=12)
            axes[i].grid(True, alpha=0.3)

        plt.xlabel('æ—¥æœŸ', fontsize=12)
        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            logger.info(f"å›æ’¤å›¾å·²ä¿å­˜: {save_path}")

        plt.show()

    def generate_full_report(self,
                             report_dir: str = "backtest_reports") -> str:
        """
        ç”Ÿæˆå®Œæ•´çš„å›æµ‹æŠ¥å‘Š
        
        Args:
            report_dir: æŠ¥å‘Šä¿å­˜ç›®å½•
            
        Returns:
            str: æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        if not self.portfolios:
            raise ValueError("è¯·å…ˆè¿è¡Œå›æµ‹")

        # åˆ›å»ºæŠ¥å‘Šç›®å½•
        report_path = Path(report_dir)
        report_path.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # ç”Ÿæˆå¯¹æ¯”è¡¨
        comparison_df = self.get_comparison_table()
        comparison_file = report_path / f"factor_comparison_{timestamp}.csv"
        comparison_df.to_csv(comparison_file, encoding='utf-8-sig')

        # ç”Ÿæˆå›¾è¡¨
        returns_chart = report_path / f"cumulative_returns_{timestamp}.png"
        self.plot_cumulative_returns(save_path=str(returns_chart))

        drawdown_chart = report_path / f"drawdown_analysis_{timestamp}.png"
        self.plot_drawdown_analysis(save_path=str(drawdown_chart))

        # ç”Ÿæˆè¯¦ç»†ç»Ÿè®¡æŠ¥å‘Š
        report_file = report_path / f"detailed_report_{timestamp}.txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("é‡åŒ–ç­–ç•¥å›æµ‹è¯¦ç»†æŠ¥å‘Š\n")
            f.write("=" * 80 + "\n\n")

            f.write("å›æµ‹é…ç½®:\n")
            f.write(f"  è°ƒä»“é¢‘ç‡: {self.config.rebalancing_freq}\n")
            f.write(f"  åšå¤šåˆ†ä½: {self.config.top_quantile:.1%}\n")
            f.write(f"  åˆå§‹èµ„é‡‘: {self.config.initial_cash:,.0f}\n")
            f.write(f"  äº¤æ˜“è´¹ç‡: {TradingCostCalculator.calculate_total_fees(self.config):.4f}\n\n")

            f.write("æ•°æ®éªŒè¯ç»“æœ:\n")
            for key, value in self.validation_results['stats'].items():
                f.write(f"  {key}: {value}\n")
            f.write("\n")

            f.write("å› å­å¯¹æ¯”ç»“æœ:\n")
            f.write(comparison_df.to_string())
            f.write("\n\n")

        logger.info(f"å®Œæ•´æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        return str(report_path)

    def get_position_weights_by_per_weight(self, holding_signals):

        # 1. ã€æ–°å¢ã€‘åˆ›å»ºç›®æ ‡æƒé‡çŸ©é˜µ
        # 1.1 è®¡ç®—æ¯æ—¥åº”æŒæœ‰çš„è‚¡ç¥¨æ€»æ•°
        num_positions = holding_signals.sum(axis=1)

        # 1.2 è®¡ç®—æ¯æ—¥çš„ç­‰æƒæƒé‡ (ä¾‹å¦‚ï¼ŒæŒæœ‰10åªè‚¡ç¥¨ï¼Œæ¯åªæƒé‡ä¸º 1/10 = 0.1)
        #     ä¸ºé¿å…é™¤ä»¥é›¶ (åœ¨æ²¡æœ‰æŒä»“çš„æ—¥å­)ï¼Œä½¿ç”¨ .replace(np.inf, 0)
        target_weights = (1 / num_positions).replace([np.inf, -np.inf], 0)

        # 1.3 å°†æ¯æ—¥æƒé‡å€¼å¹¿æ’­åˆ°å½“å¤©çš„æŒä»“è‚¡ç¥¨ä¸Šï¼Œå½¢æˆä¸€ä¸ªä¸ aholding_signals å½¢çŠ¶ç›¸åŒçš„æƒé‡çŸ©é˜µ
        #     ä¸æŒæœ‰(False)çš„è‚¡ç¥¨ï¼Œæƒé‡è‡ªç„¶ä¸º 0
        weights_df = holding_signals.mul(target_weights, axis=0)
        return weights_df

    def debug_signal_generation(self, holding_signals, config,entry_signals, exit_signals,weights_df,sidx,eidx):
        logger.info("ğŸ” ä¿¡å·è°ƒè¯•åˆ†æå¼€å§‹")
        # æ£€æŸ¥å‰å‡ å¤©çš„ä¿¡å·æƒ…å†µ
        sample_dates = generate_rebalance_dates(holding_signals.index,config.rebalancing_freq)

        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ä¿¡å·éƒ½æ˜¯False
        total_entries = entry_signals.sum().sum()
        total_exits = exit_signals.sum().sum()

        if total_entries == 0 or total_exits==0:
            raise ValueError("âŒ ä¸¥é‡é—®é¢˜ï¼šæ²¡æœ‰ç”Ÿæˆä»»ä½•ä¹°å…¥ä¿¡å·ï¼ æˆ–è€… æ²¡æœ‰ä»»ä½•å–å‡ºä¿¡å·")
        logger.info(f"âœ… ä¿¡å·ç”Ÿæˆæ­£å¸¸: ä¹°å…¥{total_entries}ä¸ª, å–å‡º{total_exits}ä¸ª")



        logger.info(f"  å¹³å‡æ¯å¤©æŒä»“è‚¡ç¥¨æ•°é‡: {holding_signals.sum(axis=1).mean()}")
        ##æ£€æŸ¥æŒä»“æƒé‡ æ˜¯å¦ç­‰äº1
        logger.info(f"  æ¯å¤©å¹³å‡æŒä»“æ¯”ä¾‹: {weights_df.sum(axis=1).mean()}")
        self._debug_holding_days(holding_signals, entry_signals, exit_signals)

    def about_cash(self, portfolio):
        logger.info(f"ç°é‡‘å˜åŒ–æƒ…å†µ:")
        cash_flows  = portfolio.cash()
        initial_cash = float(cash_flows.iloc[0])
        final_cash = float(cash_flows.iloc[-1])
        pass

    def plot_cumulative_returns_curve(self,portfolio):
        cumulative_returns_builtin = (1 + portfolio.returns()).cumprod() - 1

        # ä½¿ç”¨å†…ç½®å‡½æ•°è¿˜æœ‰ä¸€ä¸ªå·¨å¤§çš„å¥½å¤„ï¼šå¯ä»¥ç›´æ¥è°ƒç”¨ vbt çš„ç»˜å›¾åŠŸèƒ½
        print("\næ­£åœ¨ç»˜åˆ¶æƒç›Šæ›²çº¿...")
        cumulative_returns_builtin.vbt.plot(title='Equity Curve').show()

    def myself_debug_data(self, origin_weights_df):
        #æŒ‰åˆ— æ•´åˆ—è‡³å°‘æœ‰ä¸€ä¸ªå€¼ä¸ä¸º0ï¼
        origin_weights_df = origin_weights_df.loc[:, origin_weights_df.any(axis=0)]
        pass

    def _debug_holding_days(self, holding_signals, entry_signals, exit_signals):
        """
        åˆ†ææŒä»“å¤©æ•°åˆ†å¸ƒï¼Œè¯†åˆ«"è€å¦–è‚¡"ï¼ˆé•¿æœŸæŒæœ‰çš„è‚¡ç¥¨ï¼‰
        
        Args:
            holding_signals: æŒä»“ä¿¡å·çŸ©é˜µ
            entry_signals: ä¹°å…¥ä¿¡å·çŸ©é˜µ  
            exit_signals: å–å‡ºä¿¡å·çŸ©é˜µ
        """
        logger.info("ğŸ•µï¸ å¼€å§‹åˆ†ææŒä»“å¤©æ•°åˆ†å¸ƒ...")
        
        # åˆ›å»ºæŒä»“å¤©æ•°ç»Ÿè®¡å­—å…¸
        stock_holding_stats = {}
        all_holding_periods = []
        
        # éå†æ¯åªè‚¡ç¥¨
        for stock in holding_signals.columns:
            stock_entries = entry_signals[stock]
            stock_exits = exit_signals[stock]
            stock_holdings = holding_signals[stock]
            
            # æ‰¾åˆ°æ‰€æœ‰ä¹°å…¥æ—¶ç‚¹
            entry_dates = stock_entries[stock_entries].index.tolist()
            exit_dates = stock_exits[stock_exits].index.tolist()
            
            if len(entry_dates) == 0:
                continue
                
            # è®¡ç®—æ¯æ¬¡æŒä»“å‘¨æœŸ
            holding_periods = []
            
            for entry_date in entry_dates:
                # æ‰¾åˆ°å¯¹åº”çš„å–å‡ºæ—¥æœŸ
                matching_exits = [exit_date for exit_date in exit_dates if exit_date > entry_date]
                
                if matching_exits:
                    exit_date = min(matching_exits)  # æœ€è¿‘çš„å–å‡ºæ—¥æœŸ
                    # è®¡ç®—æŒä»“å¤©æ•°
                    holding_days = (exit_date - entry_date).days
                    holding_periods.append(holding_days)
                    all_holding_periods.append(holding_days)
                else:
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å–å‡ºä¿¡å·ï¼Œè®¡ç®—åˆ°æœ€åä¸€å¤©çš„æŒä»“å¤©æ•°
                    last_date = holding_signals.index[-1]
                    holding_days = (last_date - entry_date).days
                    holding_periods.append(holding_days)
                    all_holding_periods.append(holding_days)
            
            if holding_periods:
                stock_holding_stats[stock] = {
                    'total_trades': len(holding_periods),
                    'min_holding_days': min(holding_periods),
                    'max_holding_days': max(holding_periods),
                    'avg_holding_days': np.mean(holding_periods),
                    'holding_periods': holding_periods
                }
        
        if not all_holding_periods:
            logger.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æŒä»“è®°å½•")
            return
            
        # æ•´ä½“ç»Ÿè®¡
        total_trades = len(all_holding_periods)
        avg_holding = np.mean(all_holding_periods)
        median_holding = np.median(all_holding_periods)
        max_holding = max(all_holding_periods)
        min_holding = min(all_holding_periods)
        
        logger.info(f"ğŸ“Š æŒä»“å¤©æ•°æ€»ä½“ç»Ÿè®¡:")
        logger.info(f"  æ€»äº¤æ˜“æ¬¡æ•°: {total_trades}")
        logger.info(f"  å¹³å‡æŒä»“å¤©æ•°: {avg_holding:.1f}å¤©")
        logger.info(f"  ä¸­ä½æ•°æŒä»“å¤©æ•°: {median_holding:.1f}å¤©")
        logger.info(f"  æœ€çŸ­æŒä»“: {min_holding}å¤©")
        logger.info(f"  æœ€é•¿æŒä»“: {max_holding}å¤©")
        
        # æŒä»“å¤©æ•°åˆ†å¸ƒ
        bins = [0, 7, 30, 60, 120, 240, float('inf')]
        bin_labels = ['<7å¤©', '7-30å¤©', '30-60å¤©', '60-120å¤©', '120-240å¤©', '>240å¤©']
        
        for i, (bin_start, bin_end) in enumerate(zip(bins[:-1], bins[1:])):
            if bin_end == float('inf'):
                count = sum(1 for days in all_holding_periods if days >= bin_start)
            else:
                count = sum(1 for days in all_holding_periods if bin_start <= days < bin_end)
            
            percentage = count / total_trades * 100
            logger.info(f"  {bin_labels[i]}: {count}æ¬¡ ({percentage:.1f}%)")
        
        # æ‰¾å‡º"è€å¦–è‚¡" - æŒä»“è¶…è¿‡120å¤©çš„è‚¡ç¥¨
        long_holding_threshold = 120
        old_monster_stocks = []
        
        for stock, stats in stock_holding_stats.items():
            max_days = stats['max_holding_days']
            if max_days >= long_holding_threshold:
                old_monster_stocks.append({
                    'stock': stock,
                    'max_holding_days': max_days,
                    'avg_holding_days': stats['avg_holding_days'],
                    'total_trades': stats['total_trades']
                })
        
        # æŒ‰æœ€é•¿æŒä»“å¤©æ•°æ’åº
        old_monster_stocks.sort(key=lambda x: x['max_holding_days'], reverse=True)
        
        if old_monster_stocks:
            logger.info(f"ğŸ‰ å‘ç°{len(old_monster_stocks)}åªè€å¦–è‚¡ (æŒä»“>{long_holding_threshold}å¤©):")
            
            # æ˜¾ç¤ºå‰10åªæœ€"å¦–"çš„è‚¡ç¥¨
            top_monsters = old_monster_stocks[:10]
            for i, stock_info in enumerate(top_monsters, 1):
                logger.info(f"  {i:2d}. {stock_info['stock']}: æœ€é•¿{stock_info['max_holding_days']}å¤©, "
                           f"å¹³å‡{stock_info['avg_holding_days']:.1f}å¤©, å…±{stock_info['total_trades']}æ¬¡äº¤æ˜“")
                
            if len(old_monster_stocks) > 10:
                logger.info(f"  ... è¿˜æœ‰{len(old_monster_stocks) - 10}åªè€å¦–è‚¡")
                
            # è¶…çº§å¦–è‚¡ - æŒä»“è¶…è¿‡240å¤©
            super_monsters = [s for s in old_monster_stocks if s['max_holding_days'] >= 240]
            if super_monsters:
                logger.info(f"ğŸ‘¹ å…¶ä¸­{len(super_monsters)}åªè¶…çº§å¦–è‚¡ (æŒä»“>240å¤©):")
                for stock_info in super_monsters:
                    logger.info(f"     {stock_info['stock']}: {stock_info['max_holding_days']}å¤©")
        else:
            logger.info(f"âœ… æ²¡æœ‰å‘ç°è€å¦–è‚¡ (æ‰€æœ‰è‚¡ç¥¨æŒä»“éƒ½<{long_holding_threshold}å¤©)")
        
        logger.info("ğŸ•µï¸ æŒä»“å¤©æ•°åˆ†æå®Œæˆ")

    def today_need_exit(self, prev_holdings, curr_holdings, not_finishied_exit):
        today_exit_signal =  ~curr_holdings & prev_holdings
        if not_finishied_exit is not None: #æ˜¨å¤©æ²¡å–å‡ºå»ï¼Œä»Šå¤©èµ¶ç´§å–ï¼
            today_exit_signal = today_exit_signal | not_finishied_exit

        return today_exit_signal


# ä¾¿æ·å‡½æ•°
def quick_factor_backtest(
        price_df: pd.DataFrame,
        factor_dict: Dict[str, pd.DataFrame],
        config: Optional[BacktestConfig] = None
) -> Tuple[Dict[str, any], pd.DataFrame]:
    """
    å¿«é€Ÿå› å­å›æµ‹å‡½æ•°
    
    Args:
        price_df: ä»·æ ¼æ•°æ®
        factor_dict: å› å­æ•°æ®å­—å…¸
        config: å›æµ‹é…ç½®
        
    Returns:
        Tuple: (å›æµ‹ç»“æœå­—å…¸, å¯¹æ¯”è¡¨)
    """
    backtester = QuantBacktester(config)
    portfolios = backtester.run_backtest(price_df, factor_dict)
    comparison_table = backtester.get_comparison_table()

    return portfolios, comparison_table


if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    logger.info("QuantBacktester ç¤ºä¾‹è¿è¡Œ")

    # è¿™é‡Œéœ€è¦ä½ æä¾›çœŸå®çš„æ•°æ®
    # price_df = load_price_data()
    # factor_dict = {
    #     'volatility_40d': load_factor_data('volatility_40d'),
    #     'composite_factor': load_factor_data('composite_factor')
    # }

    # # é…ç½®å›æµ‹å‚æ•°
    # config = BacktestConfig(
    #     top_quantile=0.2,
    #     rebalancing_freq='M',
    #     commission_rate=0.0003,
    #     slippage_rate=0.001
    # )

    # # è¿è¡Œå›æµ‹
    # backtester = QuantBacktester(config)
    # portfolios = backtester.run_backtest(price_df, factor_dict)

    # # ç”Ÿæˆå¯¹æ¯”å’ŒæŠ¥å‘Š
    # comparison_table = backtester.get_comparison_table()
    # print(comparison_table)

    # backtester.plot_cumulative_returns()
    # report_path = backtester.generate_full_report()

    logger.info("QuantBacktester ç¤ºä¾‹å®Œæˆ")
