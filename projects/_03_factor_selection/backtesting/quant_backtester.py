"""
é‡åŒ–å›æµ‹å™¨ - ä¸“ä¸šçº§å› å­ç­–ç•¥å›æµ‹å·¥å…·

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. å¤šå› å­ç­–ç•¥å›æµ‹å¯¹æ¯”
2. çœŸå®äº¤æ˜“æˆæœ¬å»ºæ¨¡
3. å®Œæ•´çš„é£é™©è°ƒæ•´æ”¶ç›Šåˆ†æ
4. å¯è§†åŒ–å’ŒæŠ¥å‘Šç”Ÿæˆ
5. å®ç›˜çº§æ•°æ®å¯¹é½å’ŒéªŒè¯

è®¾è®¡ç†å¿µï¼š
- é¢å‘å¯¹è±¡ï¼Œå¯æ‰©å±•
- æ•°æ®å®‰å…¨ï¼Œä¸¥æ ¼å¯¹é½éªŒè¯
- äº¤æ˜“æˆæœ¬çœŸå®å»ºæ¨¡
- ç»“æœå¯å¤ç°ï¼Œå¯è§£é‡Š
"""

import pandas as pd
import numpy as np
import vectorbt as vbt
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Optional, Tuple, Union
from dataclasses import dataclass
from pathlib import Path
import warnings
from datetime import datetime

from vectorbt.portfolio import CallSeqType

from quant_lib.config.logger_config import setup_logger

logger = setup_logger(__name__)
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
plt.rcParams['axes.unicode_minus'] = False


@dataclass
class BacktestConfig:
    """å›æµ‹é…ç½®å‚æ•°"""
    # ç­–ç•¥å‚æ•°
    top_quantile: float = 0.2  # åšå¤šåˆ†ä½æ•°é˜ˆå€¼ï¼ˆå‰20%ï¼‰
    rebalancing_freq: str = 'W'  # è°ƒä»“é¢‘ç‡ ('M'=æœˆæœ«, 'W'=å‘¨æœ«, 'Q'=å­£æœ«)
    
    # äº¤æ˜“æˆæœ¬å‚æ•°
    commission_rate: float = 0.0003  # ä½£é‡‘è´¹ç‡ï¼ˆä¸‡3ï¼‰
    slippage_rate: float = 0.0010  # æ»‘ç‚¹ç‡ï¼ˆåƒ1ï¼‰
    stamp_duty: float = 0.0010  # å°èŠ±ç¨ï¼ˆå•è¾¹ï¼Œå–å‡ºæ”¶å–ï¼‰
    min_commission: float = 5.0  # æœ€å°ä½£é‡‘ï¼ˆå…ƒï¼‰
    
    # å›æµ‹å‚æ•°
    initial_cash: float = 1000000.0  # åˆå§‹èµ„é‡‘ï¼ˆ100ä¸‡ï¼‰
    max_positions: int = 50  # æœ€å¤§æŒä»“æ•°é‡
    
    # é£æ§å‚æ•°
    max_weight_per_stock: float = 0.10  # å•è‚¡æœ€å¤§æƒé‡ï¼ˆ10%ï¼‰
    min_weight_threshold: float = 0.01  # æœ€å°æƒé‡é˜ˆå€¼ï¼ˆ1%ï¼‰
    
    # æ•°æ®éªŒè¯å‚æ•°
    min_data_coverage: float = 0.8  # æœ€å°æ•°æ®è¦†ç›–ç‡
    max_missing_consecutive_days: int = 5  # æœ€å¤§è¿ç»­ç¼ºå¤±å¤©æ•°


class DataValidator:
    """æ•°æ®éªŒè¯å™¨"""
    
    @staticmethod
    def validate_dataframes(price_df: pd.DataFrame, *factor_dfs: pd.DataFrame) -> Dict[str, any]:
        """
        éªŒè¯ä»·æ ¼æ•°æ®å’Œå› å­æ•°æ®çš„ä¸€è‡´æ€§
        
        Args:
            price_df: ä»·æ ¼æ•°æ®
            factor_dfs: å› å­æ•°æ®åˆ—è¡¨
            
        Returns:
            Dict: éªŒè¯ç»“æœç»Ÿè®¡
        """
        validation_results = {
            'is_valid': True,
            'errors': [],
            'warnings': [],
            'stats': {}
        }
        
        try:
            # æ£€æŸ¥ç´¢å¼•ç±»å‹
            if not isinstance(price_df.index, pd.DatetimeIndex):
                validation_results['errors'].append("ä»·æ ¼æ•°æ®ç´¢å¼•å¿…é¡»æ˜¯DatetimeIndex")
                validation_results['is_valid'] = False
            
            # æ£€æŸ¥æ•°æ®å¯¹é½
            reference_index = price_df.index
            reference_columns = price_df.columns
            
            for i, factor_df in enumerate(factor_dfs):
                factor_name = f"å› å­{i+1}"
                
                # ç´¢å¼•å¯¹é½æ£€æŸ¥
                if not factor_df.index.equals(reference_index):
                    missing_dates = reference_index.difference(factor_df.index)
                    if len(missing_dates) > 0:
                        validation_results['warnings'].append(
                            f"{factor_name}ç¼ºå¤±{len(missing_dates)}ä¸ªäº¤æ˜“æ—¥"
                        )
                
                # åˆ—å¯¹é½æ£€æŸ¥
                if not factor_df.columns.equals(reference_columns):
                    missing_stocks = reference_columns.difference(factor_df.columns)
                    if len(missing_stocks) > 0:
                        validation_results['warnings'].append(
                            f"{factor_name}ç¼ºå¤±{len(missing_stocks)}åªè‚¡ç¥¨"
                        )
            
            # ç»Ÿè®¡ä¿¡æ¯
            validation_results['stats'] = {
                'date_range': (price_df.index.min(), price_df.index.max()),
                'trading_days': len(price_df.index),
                'stock_count': len(price_df.columns),
                'data_coverage': (1 - price_df.isnull().sum().sum() / price_df.size) * 100
            }
            
            logger.info(f"æ•°æ®éªŒè¯å®Œæˆ: {validation_results['stats']}")
            
        except Exception as e:
            validation_results['errors'].append(f"éªŒè¯è¿‡ç¨‹å¼‚å¸¸: {str(e)}")
            validation_results['is_valid'] = False
        
        return validation_results
    
    @staticmethod
    def align_dataframes(price_df: pd.DataFrame, *factor_dfs: pd.DataFrame) -> Tuple[pd.DataFrame, ...]:
        """
        å¯¹é½ä»·æ ¼æ•°æ®å’Œå› å­æ•°æ®
        
        Args:
            price_df: ä»·æ ¼æ•°æ®
            factor_dfs: å› å­æ•°æ®åˆ—è¡¨
            
        Returns:
            Tuple: å¯¹é½åçš„æ•°æ®æ¡†åˆ—è¡¨
        """
        # ä½¿ç”¨vectorbtçš„å¯¹é½åŠŸèƒ½
        aligned_data = vbt.base.reshape_fns.broadcast(price_df, *factor_dfs, 
                                                     keep_pd=True, 
                                                     align_index=True, 
                                                     align_columns=True)
        
        logger.info(f"æ•°æ®å¯¹é½å®Œæˆï¼Œæœ€ç»ˆç»´åº¦: {aligned_data[0].shape}")
        return aligned_data


class StrategySignalGenerator:
    """ç­–ç•¥ä¿¡å·ç”Ÿæˆå™¨"""
    
    @staticmethod
    def generate_long_signals(
        factor_df: pd.DataFrame,
        config: BacktestConfig
    ) -> pd.DataFrame:
        """
        ç”Ÿæˆåšå¤šä¿¡å·

        Args:
            factor_df: å› å­æ•°æ®
            config: å›æµ‹é…ç½®

        Returns:
            pd.DataFrame: æŒä»“ä¿¡å·ï¼ˆTrue=æŒæœ‰ï¼ŒFalse=ä¸æŒæœ‰ï¼‰
        """
        # 1. è®¡ç®—æ¯æ—¥æ’åç™¾åˆ†ä½ï¼ˆè¶Šå¤§æ’åè¶Šé å‰ï¼‰
        ranks = factor_df.rank(axis=1, pct=True, method='average', na_option='keep')

        # 2. ç¡®å®šåšå¤šä¿¡å·ï¼ˆæ’ååœ¨å‰top_quantileï¼‰
        long_signals_raw = ranks >= (1 - config.top_quantile)

        # 3. æŒ‰è°ƒä»“é¢‘ç‡è¿›è¡Œé‡é‡‡æ ·
        # .resample().last() è·å–æ¯ä¸ªå‘¨æœŸæœ€åä¸€å¤©çš„ä¿¡å·
        # .reindex().ffill() å°†ä¿¡å·å‰å¡«å……åˆ°æ¯ä¸ªäº¤æ˜“æ—¥
        rebalance_signals = long_signals_raw.resample(config.rebalancing_freq).last()
        final_signals = rebalance_signals.reindex(factor_df.index, method='ffill')

        # 4. æ§åˆ¶æœ€å¤§æŒä»“æ•°é‡
        if config.max_positions > 0:
            final_signals = StrategySignalGenerator._limit_positions(
                final_signals, ranks, config.max_positions
            )

        logger.info(f"ä¿¡å·ç”Ÿæˆå®Œæˆï¼Œå¹³å‡æŒä»“æ•°: {final_signals.sum(axis=1).mean():.1f}")
        return final_signals.fillna(False)
    
    @staticmethod
    def _limit_positions(signals: pd.DataFrame, ranks: pd.DataFrame, max_positions: int) -> pd.DataFrame:
        """
        é™åˆ¶æœ€å¤§æŒä»“æ•°é‡ï¼Œä¼˜å…ˆé€‰æ‹©æ’åæœ€é«˜çš„è‚¡ç¥¨
        
        Args:
            signals: åŸå§‹ä¿¡å·
            ranks: æ’åæ•°æ®
            max_positions: æœ€å¤§æŒä»“æ•°
            
        Returns:
            pd.DataFrame: é™åˆ¶åçš„ä¿¡å·
        """
        limited_signals = pd.DataFrame(False, index=signals.index, columns=signals.columns)
        
        for date in signals.index:
            date_signals = signals.loc[date]
            date_ranks = ranks.loc[date]
            
            if date_signals.sum() > max_positions:
                # é€‰æ‹©æ’åæœ€é«˜çš„max_positionsåªè‚¡ç¥¨
                valid_stocks = date_signals[date_signals].index
                top_stocks = date_ranks[valid_stocks].nlargest(max_positions).index
                limited_signals.loc[date, top_stocks] = True
            else:
                limited_signals.loc[date] = date_signals
                
        return limited_signals

        # å»ºè®®æ”¾åœ¨ä½ çš„ StrategySignalGenerator ç±»ä¸­

    # å»ºè®®æ”¾åœ¨ä½ çš„ StrategySignalGenerator ç±»ä¸­
    # æ”¾åœ¨ä½ çš„ StrategySignalGenerator ç±»ä¸­

    @staticmethod
    def generate_long_holding_signals(factor_df: pd.DataFrame,price_df, config: BacktestConfig) -> pd.DataFrame:
        """
        ã€V5ã€‘ç”Ÿæˆæ¯æ—¥ç›®æ ‡â€œæŒä»“â€å¸ƒå°”çŸ©é˜µ (True/False)ã€‚
        """
        ranks = factor_df.rank(axis=1, pct=True, method='average', na_option='keep')
        snapshot_ranks = ranks.resample(config.rebalancing_freq).last().dropna(how='all')
        if snapshot_ranks.empty:
            raise ValueError("æ²¡æœ‰æœ‰æ•ˆçš„è°ƒä»“æ—¥å¿«ç…§ï¼Œè¯·æ£€æŸ¥è°ƒä»“é¢‘ç‡æˆ–æ•°æ®æ—¥æœŸèŒƒå›´")

        final_positions_snapshot = pd.DataFrame(False, index=snapshot_ranks.index, columns=snapshot_ranks.columns)
        for dt in snapshot_ranks.index:
            # 1. åŠ¨æ€ç¡®å®šå½“æ—¥çš„å¯æŠ•èµ„æ±  (å…³é”®æ­¥éª¤!)
            daily_valid_ranks = snapshot_ranks.loc[dt].dropna()

            if daily_valid_ranks.empty:
                continue  # å¦‚æœå½“å¤©æ‰€æœ‰è‚¡ç¥¨éƒ½ä¸ºNaNï¼Œåˆ™è·³è¿‡

            # 2. åœ¨å¯æŠ•èµ„æ± çš„åŸºç¡€ä¸Šï¼Œè®¡ç®—ç›®æ ‡æŒä»“æ•°
            # ä½¿ç”¨ np.ceil ç¡®ä¿è‡³å°‘é€‰æ‹©ä¸€åªè‚¡ç¥¨ï¼ˆå¦‚æœæ¯”ä¾‹å¾ˆå°ï¼‰ï¼Œå¹¶å¤„ç†è¾¹ç•Œæƒ…å†µ
            num_to_select = int(np.ceil(len(daily_valid_ranks) * config.top_quantile))

            # å…¼å®¹ max_positions è®¾ç½®
            if config.max_positions:
                num_to_select = min(num_to_select, config.max_positions)

            # 3. ä½¿ç”¨ nlargest ç›´æ¥ã€ç²¾ç¡®åœ°é€‰å‡ºTop Nçš„è‚¡ç¥¨
            chosen_stocks = daily_valid_ranks.nlargest(num_to_select).index

            # 4. æ›´æ–°æŒä»“å¿«ç…§
            final_positions_snapshot.loc[dt, chosen_stocks] = True
        # --- å¼€å§‹ä¸‰æ­¥è°ƒè¯•æ³• ---
        print("\n" + "=" * 20 + " æ³•åŒ»å¼è°ƒè¯•å¼€å§‹ " + "=" * 20)


        daily_holding_signals = final_positions_snapshot.reindex(factor_df.index, method='ffill').fillna(False)

        # daily_holding_signals = daily_holding_signals.where(factor_df.notna(), other=False)
        #  price_df å°±æ˜¯å¯¹é½åçš„ä»·æ ¼
        is_tradable = price_df.notna()  # å½“å¤©æœ‰ä»·æ ¼æ•°æ®ï¼Œå°±è®¤ä¸ºæ˜¯å¯äº¤æ˜“çš„

        # å°†ç†è®ºæŒä»“ä¿¡å·ä¸å¯äº¤æ˜“ä¿¡å·åšâ€œä¸â€è¿ç®—
        # åªæœ‰å½“â€œæˆ‘æƒ³æŒæœ‰â€ä¸”â€œå®ƒèƒ½äº¤æ˜“â€æ—¶ï¼Œæˆ‘æ‰çœŸæ­£æŒæœ‰å®ƒ
        daily_holding_signals = daily_holding_signals & is_tradable # daily_holding_signals.sum
        # æ­¥éª¤ 1: éªŒè¯è°ƒä»“å†³ç­–çš„å˜åŒ–
        # .diff() ä¼šè®¡ç®—å½“å‰è¡Œä¸ä¸Šä¸€è¡Œçš„å·®å¼‚, .abs()å–ç»å¯¹å€¼, .sum()è®¡ç®—æ€»å˜åŒ–
        turnover_counts = daily_holding_signals.astype(int).diff().abs().sum(axis=1)

        print("\n[æ­¥éª¤ 1] æ¯ä¸ªè°ƒä»“æ—¥çš„æŒä»“å˜åŠ¨è‚¡ç¥¨æ•°:")
        print(turnover_counts)

        # ç»Ÿè®¡æœ‰å¤šå°‘ä¸ªè°ƒä»“æ—¥æ˜¯å®Œå…¨æ²¡æœ‰æ¢æ‰‹çš„
        zero_turnover_days = (turnover_counts == 0).sum()
        total_rebalancing_days = len(turnover_counts)
        print(f"\nåˆ†æ: åœ¨ {total_rebalancing_days} ä¸ªè°ƒä»“æ—¥ä¸­ï¼Œæœ‰ {zero_turnover_days} å¤©çš„æŒä»“æ˜¯å®Œå…¨æ²¡æœ‰å˜åŒ–çš„ã€‚")
        print(f"æ¢æ‰‹ç‡ä¸ºé›¶çš„è°ƒä»“æ—¥å æ¯”: {zero_turnover_days / total_rebalancing_days:.2%}")
        print("=" * 60)
        return daily_holding_signals

    @staticmethod
    def generate_rebalancing_signals(holding_signals: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """
        ã€V5.1 - ç¨³å¥ç‰ˆã€‘å°†â€œæŒä»“â€çŸ©é˜µè½¬æ¢ä¸ºç²¾ç¡®çš„â€œä¹°å…¥â€å’Œâ€œå–å‡ºâ€ä¿¡å·çŸ©é˜µã€‚
        - å¢åŠ äº†å¼ºåˆ¶ç±»å‹è½¬æ¢ï¼Œå½»åº•è§£å†³ 'invert' ufunc TypeError é—®é¢˜ã€‚
        """
        logger.info("  -> V5.1: å°†æŒä»“ä¿¡å·è½¬æ¢ä¸ºä¹°å–ä¿¡å· (å·²å¢åŠ ç±»å‹ä¿æŠ¤)...")

        # ã€æ ¸å¿ƒä¿®æ­£ã€‘åœ¨ä½¿ç”¨ ~ æ“ä½œç¬¦ä¹‹å‰ï¼Œè¿›è¡Œä¸¥æ ¼çš„ç±»å‹å’Œç©ºå€¼å¤„ç†

        # 1. ç¡®ä¿å½“å‰æŒä»“ä¿¡å·æ˜¯å¸ƒå°”å‹
        current_holdings = holding_signals.astype(bool)

        # 2. å¯¹å‰ä¸€å¤©çš„æŒä»“ä¿¡å·ï¼Œå…ˆå¡«å……ç§»ä½äº§ç”Ÿçš„NaNï¼Œå†å¼ºåˆ¶è½¬ä¸ºå¸ƒå°”å‹
        prev_holdings = holding_signals.vbt.fshift(1).fillna(False).astype(bool)

        # 3. ç°åœ¨æ‰€æœ‰æ•°æ®éƒ½æ˜¯å¹²å‡€çš„å¸ƒå°”å‹ï¼Œé€»è¾‘è¿ç®—å¯ä»¥å®‰å…¨æ‰§è¡Œ
        entries = current_holdings & ~prev_holdings
        exits = ~current_holdings & prev_holdings

        return entries, exits

class TradingCostCalculator:
    """äº¤æ˜“æˆæœ¬è®¡ç®—å™¨ - é‡æ„ç‰ˆæœ¬"""
    
    @staticmethod
    def get_single_side_costs(config: BacktestConfig) -> Dict[str, float]:
        """
        è·å–å•è¾¹äº¤æ˜“æˆæœ¬
        
        Args:
            config: å›æµ‹é…ç½®
            
        Returns:
            Dict: å•è¾¹æˆæœ¬å­—å…¸
        """
        # åŸºç¡€å•è¾¹æˆæœ¬ (ä½£é‡‘)
        base_commission = config.commission_rate
        
        # å•è¾¹æ»‘ç‚¹
        single_slippage = config.slippage_rate
        
        # å°èŠ±ç¨åªåœ¨å–å‡ºæ—¶æ”¶å–ï¼Œæˆ‘ä»¬å°†å…¶åˆ†æ‘Šåˆ°ä¹°å–ä¸¤è¾¹
        # æˆ–è€…åŒ…å«åœ¨ä¸€ä¸ªç¨é«˜çš„ç»¼åˆè´¹ç‡ä¸­
        adjusted_commission = base_commission + (config.stamp_duty / 2)  # åˆ†æ‘Šå°èŠ±ç¨
        
        costs = {
            'commission': adjusted_commission,
            'slippage': single_slippage,
            'combined_fee': adjusted_commission  # vectorbtçš„feeså‚æ•°
        }
        
        logger.info(f"å•è¾¹äº¤æ˜“æˆæœ¬: ä½£é‡‘{adjusted_commission:.4f}, æ»‘ç‚¹{single_slippage:.4f}")
        return costs


class QuantBacktester:
    """é‡åŒ–å›æµ‹å™¨ä¸»ç±»"""
    
    def __init__(self, config: Optional[BacktestConfig] = None):
        """
        åˆå§‹åŒ–å›æµ‹å™¨
        
        Args:
            config: å›æµ‹é…ç½®ï¼ŒNoneæ—¶ä½¿ç”¨é»˜è®¤é…ç½®
        """
        self.config = config or BacktestConfig()
        self.validator = DataValidator()
        self.signal_generator = StrategySignalGenerator()
        self.cost_calculator = TradingCostCalculator()
        
        # å­˜å‚¨å›æµ‹ç»“æœ
        self.portfolios: Dict[str, any] = {}
        self.validation_results: Dict = {}
        
        logger.info("QuantBacktesteråˆå§‹åŒ–å®Œæˆ")
        logger.info(f"é…ç½®å‚æ•°: {self.config}")
    
    def prepare_data(
        self, 
        price_df: pd.DataFrame,
        factor_dict: Dict[str, pd.DataFrame]
    ) -> Tuple[pd.DataFrame, Dict[str, pd.DataFrame]]:
        """
        å‡†å¤‡å’ŒéªŒè¯å›æµ‹æ•°æ®
        
        Args:
            price_df: ä»·æ ¼æ•°æ®
            factor_dict: å› å­æ•°æ®å­—å…¸ {"å› å­å": DataFrame}
            
        Returns:
            Tuple: (å¯¹é½åçš„ä»·æ ¼æ•°æ®, å¯¹é½åçš„å› å­æ•°æ®å­—å…¸)
        """
        logger.info(f"å¼€å§‹å‡†å¤‡æ•°æ®ï¼Œä»·æ ¼æ•°æ®ç»´åº¦: {price_df.shape}")
        logger.info(f"å› å­æ•°é‡: {len(factor_dict)}")
        
        # éªŒè¯æ•°æ®
        factor_dfs = list(factor_dict.values())
        self.validation_results = self.validator.validate_dataframes(price_df, *factor_dfs)
        
        if not self.validation_results['is_valid']:
            raise ValueError(f"æ•°æ®éªŒè¯å¤±è´¥: {self.validation_results['errors']}")
        
        if self.validation_results['warnings']:
            for warning in self.validation_results['warnings']:
                logger.warning(warning)
        
        # å¯¹é½æ•°æ®
        aligned_data = self.validator.align_dataframes(price_df, *factor_dfs)
        aligned_price = aligned_data[0]
        aligned_factors = {
            name: aligned_data[i+1] 
            for i, name in enumerate(factor_dict.keys())
        }
        
        logger.info(f"æ•°æ®å‡†å¤‡å®Œæˆï¼Œæœ€ç»ˆç»´åº¦: {aligned_price.shape}")
        return aligned_price, aligned_factors

    def run_backtest(
            self,
            price_df: pd.DataFrame,
            factor_dict: Dict[str, pd.DataFrame]
    ) -> Dict[str, any]:
        """
        è¿è¡Œå›æµ‹ (V5 - ä½¿ç”¨ from_signals çš„æœ€ç»ˆç”Ÿäº§ç‰ˆ)
        - ä½¿ç”¨æ‰‹åŠ¨ç”Ÿæˆçš„ç²¾ç¡®è°ƒä»“ä¿¡å·ï¼Œå…¼å®¹æ‰€æœ‰vectorbtç‰ˆæœ¬
        """
        logger.info("=" * 60)
        logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œå›æµ‹ (V5 from_signals æœ€ç»ˆç‰ˆ)")
        logger.info("=" * 60)

        # 1. æ•°æ®å‡†å¤‡
        all_dfs = [price_df] + list(factor_dict.values())
        aligned_dfs = vbt.base.reshape_fns.broadcast(*all_dfs, keep_pd=True, align_index=True, align_columns=True)

        aligned_price = aligned_dfs[0]
        aligned_factors = {name: df for name, df in zip(factor_dict.keys(), aligned_dfs[1:])}

        logger.info(f"æ•°æ®å¯¹é½å®Œæˆï¼Œæœ€ç»ˆç»´åº¦: {aligned_price.shape}")

        # 2. é€ä¸ªå› å­å›æµ‹
        for factor_name, factor_data in aligned_factors.items():
            logger.info(f"ğŸš€ å¼€å§‹å›æµ‹å› å­: {factor_name}")

            # 3. ä¿¡å·ç”Ÿæˆæµæ°´çº¿
            # é¦–å…ˆï¼Œç”Ÿæˆæ¯æ—¥çš„ç›®æ ‡æŒä»“çŠ¶æ€ å…¨æ˜¯true false è¡¨ç¤ºå½“æ—¥rankæƒ…å†µçš„true flase
            holding_signals = self.signal_generator.generate_long_holding_signals(factor_data, aligned_price,self.config)

            # 1. ã€æ–°å¢ã€‘åˆ›å»ºç›®æ ‡æƒé‡çŸ©é˜µ
            # 1.1 è®¡ç®—æ¯æ—¥åº”æŒæœ‰çš„è‚¡ç¥¨æ€»æ•°
            num_positions = holding_signals.sum(axis=1)

            # 1.2 è®¡ç®—æ¯æ—¥çš„ç­‰æƒæƒé‡ (ä¾‹å¦‚ï¼ŒæŒæœ‰10åªè‚¡ç¥¨ï¼Œæ¯åªæƒé‡ä¸º 1/10 = 0.1)
            #     ä¸ºé¿å…é™¤ä»¥é›¶ (åœ¨æ²¡æœ‰æŒä»“çš„æ—¥å­)ï¼Œä½¿ç”¨ .replace(np.inf, 0)
            target_weights = (1 / num_positions).replace([np.inf, -np.inf], 0)

            # 1.3 å°†æ¯æ—¥æƒé‡å€¼å¹¿æ’­åˆ°å½“å¤©çš„æŒä»“è‚¡ç¥¨ä¸Šï¼Œå½¢æˆä¸€ä¸ªä¸ aholding_signals å½¢çŠ¶ç›¸åŒçš„æƒé‡çŸ©é˜µ
            #     ä¸æŒæœ‰(False)çš„è‚¡ç¥¨ï¼Œæƒé‡è‡ªç„¶ä¸º 0
            weights_df = holding_signals.mul(target_weights, axis=0)

            # ç„¶åï¼Œå°†æŒä»“çŠ¶æ€è½¬æ¢ä¸ºå®é™…çš„ä¹°å…¥/å–å‡ºäº¤æ˜“ä¿¡å·
            entry_signals, exit_signals = self.signal_generator.generate_rebalancing_signals(holding_signals)

            # 4. ã€æ ¸å¿ƒã€‘ä½¿ç”¨ from_signals æ‰§è¡Œå›æµ‹
            # å®ƒä¼šæ ¹æ® entry_signals åœ¨æ¯ä¸ªäº¤æ˜“æ—¥è‡ªåŠ¨ç­‰æƒé‡ä¹°å…¥
            portfolio = vbt.Portfolio.from_signals(
                close=aligned_price,
                entries=entry_signals,
                exits=exit_signals,
                # call_seq='auto',  # first sell then buy å®æµ‹!
                # size_type="percent",#å®æµ‹ï¼
                # size= pd.Series(0.75, index=aligned_price.index),  # åŠ¨æ€ä»“ä½å¤§å°
                init_cash=self.config.initial_cash,
                fees=self.config.commission_rate,
                slippage=self.config.slippage_rate,
                freq='D'  # Portfolioçš„è¿ä½œé¢‘ç‡åº”ä¸ä»·æ ¼é¢‘ç‡ä¸€è‡´
            )

            self.portfolios[factor_name] = portfolio
            print(portfolio.stats())
            # portfolio.exit_trades.recordsï¼šå°æ•°5ä½åæ›´ç²¾ç¡®
            # portfolio.entry_trades.records -
            ##
            #
            #
            #
            #

            #
            # status: äº¤æ˜“çŠ¶æ€ã€‚ï¼ˆå®æµ‹
            #
            # ä½ çœ‹åˆ°çš„ stats åº”è¯¥æ˜¯ status çš„ç¬”è¯¯ã€‚è¿™æ˜¯ä¸€ä¸ªæšä¸¾å€¼ï¼š
            #
            # 0 ä»£è¡¨ TradeStatus.Open: äº¤æ˜“å·²å¼€ä»“ï¼Œä½†å°šæœªå¹³ä»“ã€‚
            #
            # 1 ä»£è¡¨ TradeStatus.Closed: äº¤æ˜“å·²ç»å¹³ä»“ï¼Œæ˜¯ä¸€ä¸ªå®Œæ•´çš„æ¥å›ã€‚#
            portfolio.entry_trades.records - portfolio.exit_trades.records
            # 5. ç»“æœåˆ†æ (ä¸ä¹‹å‰ç‰ˆæœ¬ç›¸åŒ)
            stats = portfolio.stats()
            # åœ¨ portfolio = vbt.Portfolio.from_signals(...) ä¹‹å
            logger.info(f"ã€è¯Šæ–­ä¿¡æ¯ã€‘å› å­: {factor_name}")
            logger.info(f"  -> æ€»å…±äº§ç”Ÿçš„ä¹°å…¥ä¿¡å·ç‚¹: {entry_signals.sum().sum()}")
            logger.info(f"  -> æ€»å…±äº§ç”Ÿçš„å–å‡ºä¿¡å·ç‚¹: {exit_signals.sum().sum()}")

            # æ£€æŸ¥æœŸæœ«æŒä»“
            open_records=portfolio.positions.open.records


            # è·å–æ‰€æœ‰äº¤æ˜“è®°å½•
            trades = portfolio.trades.records

            # è¿‡æ»¤å–å‡ºæ–¹å‘ (direction == -1 è¡¨ç¤ºå–å‡º)
            sell_volume = (trades["size"] * trades["exit_price"]).sum()

            stamp_duty_cost = sell_volume * self.config.stamp_duty
            final_return_adj = stats['Total Return [%]'] - (stamp_duty_cost / self.config.initial_cash) * 100

            logger.info(f"âœ… {factor_name} å›æµ‹å®Œæˆ")
            logger.info(f"   æ€»æ”¶ç›Š: {stats['Total Return [%]']:.2f}%")
            logger.info(f"   å¤æ™®æ¯”ç‡: {stats['Sharpe Ratio']:.3f}")
            logger.info(f"   æœ€å¤§å›æ’¤: {stats['Max Drawdown [%]']:.2f}%")
            logger.info(f"   å¹´åŒ–æ¢æ‰‹ç‡: {stats['Turnover']:.2%}")
            logger.info(f"   (äº‹åè°ƒæ•´å°èŠ±ç¨å) æ€»æ”¶ç›Š: {final_return_adj:.2f}%")

        logger.info("ğŸ‰ æ‰€æœ‰å› å­å›æµ‹å®Œæˆ")
        return self.portfolios

    def get_comparison_table(self, metrics: Optional[List[str]] = None) -> pd.DataFrame:
        """
        ç”Ÿæˆå› å­å¯¹æ¯”è¡¨
        
        Args:
            metrics: è¦å¯¹æ¯”çš„æŒ‡æ ‡åˆ—è¡¨
            
        Returns:
            pd.DataFrame: å¯¹æ¯”ç»“æœè¡¨
        """
        if not self.portfolios:
            raise ValueError("è¯·å…ˆè¿è¡Œå›æµ‹")
        
        if metrics is None:
            metrics = [
                'Total Return [%]',
                'Sharpe Ratio',
                'Calmar Ratio',
                'Max Drawdown [%]',
                'Win Rate [%]',
                'Profit Factor'
            ]
        
        comparison_data = {}
        for factor_name, portfolio in self.portfolios.items():
            stats = portfolio.stats()
            comparison_data[factor_name] = stats[metrics]
        
        comparison_df = pd.DataFrame(comparison_data).T
        logger.info("å› å­å¯¹æ¯”è¡¨ç”Ÿæˆå®Œæˆ")
        return comparison_df
    
    def plot_cumulative_returns(self, 
                              figsize: Tuple[int, int] = (15, 8),
                              save_path: Optional[str] = None) -> None:
        """
        ç»˜åˆ¶ç´¯ç§¯æ”¶ç›Šç‡æ›²çº¿
        
        Args:
            figsize: å›¾ç‰‡å¤§å°
            save_path: ä¿å­˜è·¯å¾„
        """
        if not self.portfolios:
            raise ValueError("è¯·å…ˆè¿è¡Œå›æµ‹")
        
        plt.figure(figsize=figsize)
        
        for factor_name, portfolio in self.portfolios.items():
            returns = portfolio.returns()
            cumulative_returns = (1 + returns).cumprod()
            plt.plot(cumulative_returns.index, cumulative_returns.values, 
                    label=factor_name, linewidth=2)
        
        plt.title('å› å­ç­–ç•¥ç´¯ç§¯æ”¶ç›Šç‡å¯¹æ¯”', fontsize=16, fontweight='bold')
        plt.xlabel('æ—¥æœŸ', fontsize=12)
        plt.ylabel('ç´¯ç§¯æ”¶ç›Šç‡', fontsize=12)
        plt.legend(fontsize=11)
        plt.grid(True, alpha=0.3)
        plt.xticks(rotation=45)
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            logger.info(f"å›¾è¡¨å·²ä¿å­˜: {save_path}")
        
        plt.show()
    
    def plot_drawdown_analysis(self,
                             figsize: Tuple[int, int] = (15, 10),
                             save_path: Optional[str] = None) -> None:
        """
        ç»˜åˆ¶å›æ’¤åˆ†æå›¾
        
        Args:
            figsize: å›¾ç‰‡å¤§å°
            save_path: ä¿å­˜è·¯å¾„
        """
        if not self.portfolios:
            raise ValueError("è¯·å…ˆè¿è¡Œå›æµ‹")
        
        n_factors = len(self.portfolios)
        fig, axes = plt.subplots(n_factors, 1, figsize=figsize, sharex=True)
        if n_factors == 1:
            axes = [axes]
        
        for i, (factor_name, portfolio) in enumerate(self.portfolios.items()):
            drawdown = portfolio.drawdown()
            axes[i].fill_between(drawdown.index, drawdown.values, 0, 
                               color='red', alpha=0.3)
            axes[i].set_title(f'{factor_name} - å›æ’¤åˆ†æ', fontsize=14)
            axes[i].set_ylabel('å›æ’¤ (%)', fontsize=12)
            axes[i].grid(True, alpha=0.3)
        
        plt.xlabel('æ—¥æœŸ', fontsize=12)
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            logger.info(f"å›æ’¤å›¾å·²ä¿å­˜: {save_path}")
        
        plt.show()
    
    def generate_full_report(self, 
                           report_dir: str = "backtest_reports") -> str:
        """
        ç”Ÿæˆå®Œæ•´çš„å›æµ‹æŠ¥å‘Š
        
        Args:
            report_dir: æŠ¥å‘Šä¿å­˜ç›®å½•
            
        Returns:
            str: æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        if not self.portfolios:
            raise ValueError("è¯·å…ˆè¿è¡Œå›æµ‹")
        
        # åˆ›å»ºæŠ¥å‘Šç›®å½•
        report_path = Path(report_dir)
        report_path.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ç”Ÿæˆå¯¹æ¯”è¡¨
        comparison_df = self.get_comparison_table()
        comparison_file = report_path / f"factor_comparison_{timestamp}.csv"
        comparison_df.to_csv(comparison_file, encoding='utf-8-sig')
        
        # ç”Ÿæˆå›¾è¡¨
        returns_chart = report_path / f"cumulative_returns_{timestamp}.png"
        self.plot_cumulative_returns(save_path=str(returns_chart))
        
        drawdown_chart = report_path / f"drawdown_analysis_{timestamp}.png" 
        self.plot_drawdown_analysis(save_path=str(drawdown_chart))
        
        # ç”Ÿæˆè¯¦ç»†ç»Ÿè®¡æŠ¥å‘Š
        report_file = report_path / f"detailed_report_{timestamp}.txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("é‡åŒ–ç­–ç•¥å›æµ‹è¯¦ç»†æŠ¥å‘Š\n") 
            f.write("=" * 80 + "\n\n")
            
            f.write("å›æµ‹é…ç½®:\n")
            f.write(f"  è°ƒä»“é¢‘ç‡: {self.config.rebalancing_freq}\n")
            f.write(f"  åšå¤šåˆ†ä½: {self.config.top_quantile:.1%}\n")
            f.write(f"  åˆå§‹èµ„é‡‘: {self.config.initial_cash:,.0f}\n")
            f.write(f"  äº¤æ˜“è´¹ç‡: {TradingCostCalculator.calculate_total_fees(self.config):.4f}\n\n")
            
            f.write("æ•°æ®éªŒè¯ç»“æœ:\n")
            for key, value in self.validation_results['stats'].items():
                f.write(f"  {key}: {value}\n")
            f.write("\n")
            
            f.write("å› å­å¯¹æ¯”ç»“æœ:\n")
            f.write(comparison_df.to_string())
            f.write("\n\n")
        
        logger.info(f"å®Œæ•´æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        return str(report_path)


# ä¾¿æ·å‡½æ•°
def quick_factor_backtest(
    price_df: pd.DataFrame,
    factor_dict: Dict[str, pd.DataFrame],
    config: Optional[BacktestConfig] = None
) -> Tuple[Dict[str, any], pd.DataFrame]:
    """
    å¿«é€Ÿå› å­å›æµ‹å‡½æ•°
    
    Args:
        price_df: ä»·æ ¼æ•°æ®
        factor_dict: å› å­æ•°æ®å­—å…¸
        config: å›æµ‹é…ç½®
        
    Returns:
        Tuple: (å›æµ‹ç»“æœå­—å…¸, å¯¹æ¯”è¡¨)
    """
    backtester = QuantBacktester(config)
    portfolios = backtester.run_backtest(price_df, factor_dict)
    comparison_table = backtester.get_comparison_table()
    
    return portfolios, comparison_table


if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    logger.info("QuantBacktester ç¤ºä¾‹è¿è¡Œ")
    
    # è¿™é‡Œéœ€è¦ä½ æä¾›çœŸå®çš„æ•°æ®
    # price_df = load_price_data()
    # factor_dict = {
    #     'volatility_40d': load_factor_data('volatility_40d'),
    #     'composite_factor': load_factor_data('composite_factor')
    # }
    
    # # é…ç½®å›æµ‹å‚æ•°
    # config = BacktestConfig(
    #     top_quantile=0.2,
    #     rebalancing_freq='M',
    #     commission_rate=0.0003,
    #     slippage_rate=0.001
    # )
    
    # # è¿è¡Œå›æµ‹
    # backtester = QuantBacktester(config)
    # portfolios = backtester.run_backtest(price_df, factor_dict)
    
    # # ç”Ÿæˆå¯¹æ¯”å’ŒæŠ¥å‘Š
    # comparison_table = backtester.get_comparison_table()
    # print(comparison_table)
    
    # backtester.plot_cumulative_returns()
    # report_path = backtester.generate_full_report()
    
    logger.info("QuantBacktester ç¤ºä¾‹å®Œæˆ")