"""
ICåŠ æƒå› å­åˆæˆä½¿ç”¨ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æ–°çš„ICåŠ æƒåˆæˆåŠŸèƒ½
"""

from pathlib import Path
import pandas as pd
from typing import List

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from projects._03_factor_selection.data_manager.data_manager import DataManager
from projects._03_factor_selection.factor_manager.factor_manager import FactorManager  
from projects._03_factor_selection.factor_manager.factor_analyzer.factor_analyzer import FactorAnalyzer
from projects._03_factor_selection.utils.factor_processor import FactorProcessor
from projects._03_factor_selection.factor_manager.factor_composite.ic_weighted_synthesizer import (
    ICWeightedSynthesizer, 
    FactorWeightingConfig
)
from quant_lib.config.logger_config import setup_logger

logger = setup_logger(__name__)


def create_advanced_weighting_config() -> FactorWeightingConfig:
    """åˆ›å»ºé€‚åˆå®ç›˜çš„ICæƒé‡é…ç½®"""
    return FactorWeightingConfig(
        # æ›´ä¸¥æ ¼çš„ç­›é€‰æ ‡å‡†ï¼Œç¡®ä¿å› å­è´¨é‡
        min_ic_mean=0.025,           # æé«˜ICå‡å€¼è¦æ±‚
        min_ic_ir=0.35,              # æé«˜ä¿¡æ¯æ¯”ç‡è¦æ±‚
        min_ic_win_rate=0.52,        # ç•¥å¾®æé«˜èƒœç‡è¦æ±‚
        max_ic_p_value=0.05,         # æ›´ä¸¥æ ¼çš„æ˜¾è‘—æ€§è¦æ±‚
        
        # å®ç›˜å‹å¥½çš„æƒé‡è®¾ç½®
        max_single_weight=0.40,      # é¿å…å•å› å­æƒé‡è¿‡å¤§
        min_single_weight=0.08,      # ç¡®ä¿å…¥é€‰å› å­æœ‰æ„ä¹‰æƒé‡
        max_factors_count=6,         # æ§åˆ¶å› å­æ•°é‡ï¼Œé™ä½å¤æ‚åº¦
        
        # ç›¸å…³æ€§æ§åˆ¶
        correlation_threshold=0.65,   # é™ä½ç›¸å…³æ€§é˜ˆå€¼
        
        # ICè¯„ä¼°å‘¨æœŸ
        lookback_periods=['5d', '21d']  # çŸ­æœŸ+ä¸­æœŸè¡¨ç°
    )


def demonstrate_ic_weighted_synthesis():
    """æ¼”ç¤ºICåŠ æƒå› å­åˆæˆå®Œæ•´æµç¨‹"""
    
    print("ğŸš€ ICåŠ æƒå› å­åˆæˆæ¼”ç¤ºå¼€å§‹...")
    
    # 1. åˆå§‹åŒ–åŸºç¡€ç»„ä»¶
    config_path = Path(__file__).parent.parent.parent / 'factory' / 'config.yaml'
    
    data_manager = DataManager(config_path)
    data_manager.prepare_basic_data()
    
    factor_manager = FactorManager(data_manager)
    factor_analyzer = FactorAnalyzer(factor_manager=factor_manager)
    factor_processor = FactorProcessor(data_manager.config)
    
    # 2. åˆ›å»ºICåŠ æƒåˆæˆå™¨
    weighting_config = create_advanced_weighting_config()
    synthesizer = ICWeightedSynthesizer(
        factor_manager=factor_manager,
        factor_analyzer=factor_analyzer, 
        factor_processor=factor_processor,
        config=weighting_config
    )
    
    # 3. å®šä¹‰å€™é€‰å› å­ï¼ˆå»ºè®®é€‰æ‹©ä¸åŒç±»åˆ«çš„å› å­ï¼‰
    candidate_factors = [
        # ä»·å€¼å› å­
        'bm_ratio', 'ep_ratio', 'sp_ratio',
        # è´¨é‡å› å­  
        'roe_ttm', 'gross_margin_ttm',
        # æˆé•¿å› å­
        'net_profit_growth_ttm', 'revenue_growth_ttm',
        # åŠ¨é‡å› å­
        'momentum_120d', 'momentum_20d',
        # æµåŠ¨æ€§å› å­
        'amihud_liquidity', 'turnover_rate_90d_mean',
        # é£é™©å› å­
        'volatility_120d', 'volatility_90d'
    ]
    
    stock_pool_name = 'institutional_stock_pool'  # æˆ–ä½ é…ç½®çš„å…¶ä»–è‚¡ç¥¨æ± 
    composite_factor_name = 'IC_Weighted_Alpha_V1'
    
    try:
        # 4. æ‰§è¡ŒICåŠ æƒåˆæˆ
        logger.info(f"å¼€å§‹åˆæˆå› å­: {composite_factor_name}")
        
        composite_factor_df, synthesis_report = synthesizer.synthesize_ic_weighted_factor(
            composite_factor_name=composite_factor_name,
            stock_pool_index_name=stock_pool_name,
            candidate_factor_names=candidate_factors,
            force_recalculate_ic=False  # ä½¿ç”¨ç¼“å­˜çš„ICæ•°æ®
        )
        
        # 5. æ˜¾ç¤ºåˆæˆæŠ¥å‘Š
        synthesizer.print_synthesis_report(synthesis_report)
        
        # 6. ä¿å­˜åˆæˆå› å­ç”¨äºåç»­æµ‹è¯•
        save_composite_factor(composite_factor_df, composite_factor_name, synthesis_report)
        
        # 7. å¿«é€Ÿè´¨é‡æ£€æŸ¥
        perform_quick_quality_check(composite_factor_df, composite_factor_name)
        
        logger.info("âœ… ICåŠ æƒå› å­åˆæˆæ¼”ç¤ºå®Œæˆï¼")
        
        return composite_factor_df, synthesis_report
        
    except Exception as e:
        logger.error(f"âŒ åˆæˆè¿‡ç¨‹å‡ºç°é”™è¯¯: {e}")
        raise


def save_composite_factor(factor_df: pd.DataFrame, factor_name: str, report: dict):
    """ä¿å­˜åˆæˆå› å­å’ŒæŠ¥å‘Š"""
    try:
        # åˆ›å»ºç»“æœç›®å½•
        results_dir = Path(__file__).parent.parent.parent / 'results' / 'composite_factors'
        results_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜å› å­æ•°æ®
        factor_file = results_dir / f"{factor_name}_factor_data.parquet"
        factor_df.to_parquet(factor_file)
        
        # ä¿å­˜åˆæˆæŠ¥å‘Š
        import json
        report_copy = report.copy()
        
        # å¤„ç†æ—¶é—´æˆ³åºåˆ—åŒ–
        if 'synthesis_timestamp' in report_copy:
            report_copy['synthesis_timestamp'] = report_copy['synthesis_timestamp'].isoformat()
        
        report_file = results_dir / f"{factor_name}_synthesis_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_copy, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ’¾ åˆæˆç»“æœå·²ä¿å­˜:")
        logger.info(f"  å› å­æ•°æ®: {factor_file}")
        logger.info(f"  åˆæˆæŠ¥å‘Š: {report_file}")
        
    except Exception as e:
        logger.error(f"âš ï¸ ä¿å­˜åˆæˆç»“æœå¤±è´¥: {e}")


def perform_quick_quality_check(factor_df: pd.DataFrame, factor_name: str):
    """å¯¹åˆæˆå› å­è¿›è¡Œå¿«é€Ÿè´¨é‡æ£€æŸ¥"""
    logger.info(f"\nğŸ“Š {factor_name} å¿«é€Ÿè´¨é‡æ£€æŸ¥:")
    
    # åŸºæœ¬ç»Ÿè®¡
    all_values = factor_df.stack().dropna()
    logger.info(f"  ğŸ“ˆ æ•°æ®è¦†ç›–: {len(all_values):,} ä¸ªæœ‰æ•ˆè§‚æµ‹å€¼")
    logger.info(f"  ğŸ“Š ç»Ÿè®¡ç‰¹å¾: å‡å€¼={all_values.mean():.4f}, æ ‡å‡†å·®={all_values.std():.4f}")
    logger.info(f"  ğŸ“ æ•°æ®èŒƒå›´: [{all_values.min():.4f}, {all_values.max():.4f}]")
    
    # æ¯æ—¥æœ‰æ•ˆè‚¡ç¥¨æ•°
    daily_counts = factor_df.notna().sum(axis=1)
    logger.info(f"  ğŸ“… æ¯æ—¥æœ‰æ•ˆè‚¡ç¥¨æ•°: å‡å€¼={daily_counts.mean():.1f}, æœ€å°={daily_counts.min()}, æœ€å¤§={daily_counts.max()}")
    
    # ç¨³å®šæ€§æ£€æŸ¥
    monthly_means = factor_df.resample('M').apply(lambda x: x.stack().mean())
    monthly_stability = monthly_means.std()
    logger.info(f"  ğŸ”„ æœˆåº¦ç¨³å®šæ€§: {monthly_stability:.4f} (è¶Šå°è¶Šç¨³å®š)")
    
    # åˆ†ä½æ•°æ£€æŸ¥
    q1, q5, q95, q99 = all_values.quantile([0.01, 0.05, 0.95, 0.99])
    logger.info(f"  ğŸ“Š åˆ†ä½æ•°æ£€æŸ¥: P1={q1:.3f}, P5={q5:.3f}, P95={q95:.3f}, P99={q99:.3f}")


def load_and_test_composite_factor(factor_name: str):
    """åŠ è½½å·²ä¿å­˜çš„åˆæˆå› å­å¹¶è¿›è¡Œæµ‹è¯•"""
    try:
        results_dir = Path(__file__).parent.parent.parent / 'results' / 'composite_factors' 
        factor_file = results_dir / f"{factor_name}_factor_data.parquet"
        
        if not factor_file.exists():
            logger.error(f"âŒ æœªæ‰¾åˆ°å› å­æ–‡ä»¶: {factor_file}")
            return None
        
        # åŠ è½½å› å­æ•°æ®
        factor_df = pd.read_parquet(factor_file)
        logger.info(f"ğŸ“¥ æˆåŠŸåŠ è½½åˆæˆå› å­: {factor_name}")
        
        # è¿™é‡Œå¯ä»¥è°ƒç”¨ä½ çš„å› å­æµ‹è¯•æµç¨‹
        # factor_analyzer.test_factor_entity_service(factor_name, factor_df, need_process_factor=False)
        
        return factor_df
        
    except Exception as e:
        logger.error(f"âŒ åŠ è½½å› å­å¤±è´¥: {e}")
        return None


if __name__ == "__main__":
    # æ¼”ç¤ºå®Œæ•´æµç¨‹
    try:
        composite_df, report = demonstrate_ic_weighted_synthesis()
        
        # å¯ä»¥ç»§ç»­è¿›è¡Œå› å­æµ‹è¯•
        print("\nğŸ’¡ æ¥ä¸‹æ¥å¯ä»¥:")
        print("1. å¯¹åˆæˆå› å­è¿›è¡Œå®Œæ•´çš„å•å› å­æµ‹è¯•")
        print("2. ä¸åŸæœ‰çš„ç­‰æƒåˆæˆå› å­è¿›è¡Œå¯¹æ¯”")
        print("3. æ„å»ºåŸºäºæ­¤åˆæˆå› å­çš„äº¤æ˜“ç­–ç•¥")
        
    except Exception as e:
        print(f"æ¼”ç¤ºè¿‡ç¨‹å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()