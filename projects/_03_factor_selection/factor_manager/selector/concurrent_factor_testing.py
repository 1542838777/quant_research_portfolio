"""
å¹¶å‘å› å­æµ‹è¯•ç³»ç»Ÿ - å®‰å…¨ä¸”é«˜æ•ˆçš„å¤šå› å­å¹¶è¡Œæµ‹è¯•

æ ¸å¿ƒç‰¹æ€§:
1. çº¿ç¨‹å®‰å…¨çš„æ•°æ®éš”ç¦»
2. è¿›ç¨‹æ± å¹¶å‘ï¼Œé¿å…æ•°æ®é”™ä¹±
3. å®æ—¶è¿›åº¦ç›‘æ§
4. å¤±è´¥é‡è¯•æœºåˆ¶
5. ç»“æœæ±‡æ€»ä¸æŠ¥å‘Š

è®¾è®¡åŸç†:
- æ¯ä¸ªè¿›ç¨‹ç‹¬ç«‹åˆ›å»ºæ•°æ®ç®¡ç†å™¨å®ä¾‹ï¼Œé¿å…å…±äº«çŠ¶æ€
- ä½¿ç”¨è¿›ç¨‹æ± è€Œéçº¿ç¨‹æ± ï¼Œç¡®ä¿å†…å­˜éš”ç¦»
- ç»“æœé€šè¿‡åºåˆ—åŒ–ä¼ é€’ï¼Œé¿å…å¯¹è±¡å…±äº«
"""

import json
import time
import traceback
from concurrent.futures import ProcessPoolExecutor, as_completed
from multiprocessing import Manager
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
import pandas as pd
import numpy as np
import pickle
import os

from projects._03_factor_selection.config.config_file.load_config_file import _load_file
from quant_lib.config.logger_config import setup_logger

# ä¸ºæ¯ä¸ªè¿›ç¨‹è®¾ç½®æ—¥å¿—
logger = setup_logger(__name__)


def t_single_factor_isolated(
    factor_name: str, 
    stock_pool_name: str, 
    config_path: str, 
    experiments_path: str,
    process_id: int,
    shared_progress: Optional[Any] = None
) -> Dict:
    """
    åœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­æµ‹è¯•å•ä¸ªå› å­
    
    Args:
        factor_name: å› å­åç§°
        stock_pool_name: è‚¡ç¥¨æ± åç§°  
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        experiments_path: å®éªŒé…ç½®è·¯å¾„
        process_id: è¿›ç¨‹ID
        shared_progress: å…±äº«è¿›åº¦å¯¹è±¡
        
    Returns:
        Dict: æµ‹è¯•ç»“æœå­—å…¸
    """
    
    # æ¯ä¸ªè¿›ç¨‹è®¾ç½®ç‹¬ç«‹çš„æ—¥å¿—
    process_logger = setup_logger(f"{__name__}_process_{process_id}")
    
    start_time = time.time()
    result = {
        'factor_name': factor_name,
        'stock_pool_name': stock_pool_name,
        'process_id': process_id,
        'status': 'failed',
        'error_message': None,
        'execution_time': 0,
        'test_results': None
    }
    
    try:
        process_logger.info(f"ğŸš€ è¿›ç¨‹{process_id}: å¼€å§‹æµ‹è¯•å› å­ {factor_name}")
        
        # åœ¨è¿›ç¨‹å†…éƒ¨å¯¼å…¥ï¼Œé¿å…è·¨è¿›ç¨‹å…±äº«
        from projects._03_factor_selection.data_manager.data_manager import DataManager
        from projects._03_factor_selection.factor_manager.factor_manager import FactorManager
        from projects._03_factor_selection.factor_manager.factor_analyzer.factor_analyzer import FactorAnalyzer
        
        # ä¸ºæ¯ä¸ªè¿›ç¨‹åˆ›å»ºç‹¬ç«‹çš„æ•°æ®ç®¡ç†å™¨å®ä¾‹
        process_logger.info(f"  ğŸ“Š è¿›ç¨‹{process_id}: åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨...")
        data_manager = DataManager(
            config_path=config_path, 
            experiments_config_path=experiments_path
        )
        
        # å‡†å¤‡æ•°æ®ï¼ˆæ¯ä¸ªè¿›ç¨‹ç‹¬ç«‹åŠ è½½ï¼‰
        process_logger.info(f"  ğŸ“ˆ è¿›ç¨‹{process_id}: å‡†å¤‡åŸºç¡€æ•°æ®...")
        data_manager.prepare_basic_data()
        
        # åˆ›å»ºå› å­ç®¡ç†å™¨
        factor_manager = FactorManager(data_manager)
        factor_manager.clear_cache()  # ç¡®ä¿ç¼“å­˜æ¸…æ´
        
        # åˆ›å»ºå› å­åˆ†æå™¨
        factor_analyzer = FactorAnalyzer(factor_manager=factor_manager)
        
        # æ‰§è¡Œå› å­æµ‹è¯•
        process_logger.info(f"  ğŸ”¬ è¿›ç¨‹{process_id}: æ‰§è¡Œå› å­æµ‹è¯•...")
        test_results = factor_analyzer.test_factor_entity_service_route(
            factor_name=factor_name,
            stock_pool_index_name=stock_pool_name
        )
        
        # æå–å…³é”®ç»“æœï¼ˆåªä¿ç•™å¯åºåˆ—åŒ–çš„éƒ¨åˆ†ï¼‰
        serializable_results = extract_serializable_results(test_results, process_logger)
        
        result.update({
            'status': 'success',
            'test_results': serializable_results,
            'execution_time': time.time() - start_time
        })
        
        process_logger.info(f"âœ… è¿›ç¨‹{process_id}: å› å­ {factor_name} æµ‹è¯•æˆåŠŸ "
                          f"(è€—æ—¶: {result['execution_time']:.1f}ç§’)")
        
        # æ›´æ–°å…±äº«è¿›åº¦
        if shared_progress:
            try:
                with shared_progress.get_lock():
                    shared_progress.value += 1
            except AttributeError:
                # å¦‚æœæ˜¯ValueProxyå¯¹è±¡ï¼Œç›´æ¥è®¿é—®value
                shared_progress.value += 1
                
    except Exception as e:
        error_msg = str(e)
        error_traceback = traceback.format_exc()
        
        result.update({
            'status': 'failed', 
            'error_message': error_msg,
            'error_traceback': error_traceback,
            'execution_time': time.time() - start_time
        })
        
        process_logger.error(f"âŒ è¿›ç¨‹{process_id}: å› å­ {factor_name} æµ‹è¯•å¤±è´¥: {error_msg}")
        process_logger.debug(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯:\\n{error_traceback}")
        
        # æ›´æ–°å…±äº«è¿›åº¦
        if shared_progress:
            try:
                with shared_progress.get_lock():
                    shared_progress.value += 1
            except AttributeError:
                # å¦‚æœæ˜¯ValueProxyå¯¹è±¡ï¼Œç›´æ¥è®¿é—®value
                shared_progress.value += 1
    
    return result


def extract_serializable_results(test_results: Dict, logger) -> Dict:
    """
    æå–å¯åºåˆ—åŒ–çš„æµ‹è¯•ç»“æœ
    é¿å…ä¼ é€’å¤æ‚å¯¹è±¡å¯¼è‡´çš„åºåˆ—åŒ–é—®é¢˜
    """
    
    serializable = {}
    
    try:
        # æå–ICç›¸å…³ç»“æœ
        if 'ic_stats' in test_results:
            serializable['ic_stats'] = test_results['ic_stats']
        
        # æå–åˆ†å±‚å›æµ‹ç»“æœ
        if 'quantile_stats' in test_results:
            serializable['quantile_stats'] = test_results['quantile_stats']
        
        # æå–Fama-MacBethç»“æœ
        if 'fm_stats' in test_results:
            serializable['fm_stats'] = test_results['fm_stats']
            
        # æå–ç»¼åˆå¾—åˆ†
        if 'comprehensive_scores' in test_results:
            serializable['comprehensive_scores'] = test_results['comprehensive_scores']
            
        # æå–å› å­åŸºç¡€ç»Ÿè®¡
        if 'factor_basic_stats' in test_results:
            serializable['factor_basic_stats'] = test_results['factor_basic_stats']
            
    except Exception as e:
        logger.warning(f"æå–åºåˆ—åŒ–ç»“æœæ—¶å‡ºé”™: {e}")
        serializable['extraction_error'] = str(e)
    
    return serializable


class ConcurrentFactorTester:
    """å¹¶å‘å› å­æµ‹è¯•å™¨"""
    
    def __init__(self, config_path: str, experiments_path: str, max_workers: int = 4):
        """
        åˆå§‹åŒ–å¹¶å‘æµ‹è¯•å™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            experiments_path: å®éªŒé…ç½®è·¯å¾„  
            max_workers: æœ€å¤§å¹¶å‘è¿›ç¨‹æ•°
        """
        self.config_path = str(Path(config_path).absolute())
        self.experiments_path = str(Path(experiments_path).absolute())
        self.max_workers = max_workers
        self.results = []
        
        logger.info(f"ğŸ”§ åˆå§‹åŒ–å¹¶å‘å› å­æµ‹è¯•å™¨ (æœ€å¤§å¹¶å‘æ•°: {max_workers})")
        
    def run_batch_testing(self, test_configs: List[Dict]) -> List[Dict]:
        """
        æ‰§è¡Œæ‰¹é‡å¹¶å‘æµ‹è¯•
        
        Args:
            test_configs: æµ‹è¯•é…ç½®åˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å« factor_name å’Œ stock_pool_name
            
        Returns:
            List[Dict]: æ‰€æœ‰æµ‹è¯•ç»“æœ
        """
        
        total_tests = len(test_configs)
        logger.info(f"ğŸš€ å¼€å§‹å¹¶å‘æ‰¹é‡æµ‹è¯• {total_tests} ä¸ªå› å­...")
        
        # åˆ›å»ºå…±äº«è¿›åº¦è®¡æ•°å™¨
        with Manager() as manager:
            shared_progress = manager.Value('i', 0)
            
            # åˆ›å»ºè¿›ç¨‹æ± å¹¶æäº¤ä»»åŠ¡
            with ProcessPoolExecutor(max_workers=self.max_workers) as executor:
                
                # æäº¤æ‰€æœ‰æµ‹è¯•ä»»åŠ¡
                future_to_config = {}
                for i, config in enumerate(test_configs):
                    future = executor.submit(
                        t_single_factor_isolated,
                        factor_name=config['factor_name'],
                        stock_pool_name=config['stock_pool_name'],
                        config_path=self.config_path,
                        experiments_path=self.experiments_path,
                        process_id=i,
                        shared_progress=shared_progress
                    )
                    future_to_config[future] = config
                
                # ç›‘æ§æ‰§è¡Œè¿›åº¦
                results = []
                start_time = time.time()
                
                for future in as_completed(future_to_config):
                    result = future.result()
                    results.append(result)
                    
                    # å®æ—¶è¿›åº¦æŠ¥å‘Š
                    completed = len(results)
                    elapsed = time.time() - start_time
                    avg_time = elapsed / completed
                    eta = avg_time * (total_tests - completed)
                    
                    if result['status'] == 'success':
                        logger.info(f"âœ… [{completed}/{total_tests}] {result['factor_name']} å®Œæˆ "
                                  f"(è€—æ—¶: {result['execution_time']:.1f}s, é¢„è®¡å‰©ä½™: {eta:.1f}s)")
                    else:
                        logger.error(f"âŒ [{completed}/{total_tests}] {result['factor_name']} å¤±è´¥: "
                                   f"{result['error_message']}")
        
        self.results = results
        self._generate_summary_report(results)
        
        return results
    
    def _generate_summary_report(self, results: List[Dict]):
        """ç”Ÿæˆæµ‹è¯•æ±‡æ€»æŠ¥å‘Š"""
        
        total_tests = len(results)
        successful_tests = [r for r in results if r['status'] == 'success']
        failed_tests = [r for r in results if r['status'] == 'failed']
        
        total_time = sum(r['execution_time'] for r in results)
        avg_time = total_time / total_tests if total_tests > 0 else 0
        
        logger.info("\\n" + "="*60)
        logger.info("ğŸ“Š å¹¶å‘å› å­æµ‹è¯•æ±‡æ€»æŠ¥å‘Š")
        logger.info("="*60)
        logger.info(f"ğŸ¯ æ€»æµ‹è¯•æ•°é‡: {total_tests}")
        logger.info(f"âœ… æˆåŠŸæµ‹è¯•: {len(successful_tests)} ({len(successful_tests)/total_tests*100:.1f}%)")
        logger.info(f"âŒ å¤±è´¥æµ‹è¯•: {len(failed_tests)} ({len(failed_tests)/total_tests*100:.1f}%)")
        logger.info(f"â±ï¸  æ€»æ‰§è¡Œæ—¶é—´: {total_time:.1f}ç§’")
        logger.info(f"ğŸ“ˆ å¹³å‡æµ‹è¯•æ—¶é—´: {avg_time:.1f}ç§’")
        
        if failed_tests:
            logger.info(f"\\nâŒ å¤±è´¥å› å­åˆ—è¡¨:")
            for test in failed_tests:
                logger.info(f"  - {test['factor_name']}: {test['error_message']}")
        
        if successful_tests:
            logger.info(f"\\nğŸ† æˆåŠŸå› å­å‰5å (æŒ‰æ‰§è¡Œæ—¶é—´):")
            sorted_successful = sorted(successful_tests, key=lambda x: x['execution_time'])
            for i, test in enumerate(sorted_successful[:5], 1):
                logger.info(f"  {i}. {test['factor_name']}: {test['execution_time']:.1f}ç§’")
    
    def save_results(self, output_path: Optional[str] = None):
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        
        if not self.results:
            logger.warning("æ²¡æœ‰å¯ä¿å­˜çš„æµ‹è¯•ç»“æœ")
            return
        
        if output_path is None:
            timestamp = pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")
            output_path = f"concurrent_factor_test_results_{timestamp}.json"
        
        try:
            # å‡†å¤‡ä¿å­˜çš„æ•°æ®
            save_data = {
                'metadata': {
                    'test_timestamp': pd.Timestamp.now().isoformat(),
                    'total_factors': len(self.results),
                    'successful_factors': len([r for r in self.results if r['status'] == 'success']),
                    'config_path': self.config_path,
                    'max_workers': self.max_workers
                },
                'results': self.results
            }
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(save_data, f, indent=2, ensure_ascii=False, default=str)
            
            logger.info(f"ğŸ’¾ æµ‹è¯•ç»“æœå·²ä¿å­˜è‡³: {output_path}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜ç»“æœå¤±è´¥: {e}")


def create_test_configs_from_experiments(experiments_path: str) -> List[Dict]:
    """ä»å®éªŒé…ç½®æ–‡ä»¶åˆ›å»ºæµ‹è¯•é…ç½®"""
    
    # è¿™é‡Œéœ€è¦æ ¹æ®ä½ çš„experiments.yamlæ ¼å¼æ¥è°ƒæ•´
    try:
        import yaml
        with open(experiments_path, 'r', encoding='utf-8') as f:
            experiments = yaml.safe_load(f)
        
        test_configs = []
        
        # æ ¹æ®ä½ çš„å®éªŒé…ç½®æ ¼å¼æå–å› å­å’Œè‚¡ç¥¨æ± é…ç½®
        if 'experiments' in experiments:
            for exp in experiments['experiments']:
                test_configs.append({
                    'factor_name': exp['factor_name'],
                    'stock_pool_name': exp.get('stock_pool_name', 'institutional_stock_pool')
                })
        
        return test_configs
        
    except Exception as e:
        logger.error(f"è§£æå®éªŒé…ç½®å¤±è´¥: {e}")
        return []


def main():
    """å¹¶å‘æµ‹è¯•ä¸»å‡½æ•°"""
    
    try:
        # é…ç½®æ–‡ä»¶è·¯å¾„
        current_dir = Path(__file__).parent
        config_path = 'D:\\lqs\\codeAbout\\py\\Quantitative\\quant_research_portfolio\\projects\\_03_factor_selection\\factory\\config.yaml'
        experiments_path = 'D:\\lqs\\codeAbout\\py\\Quantitative\\quant_research_portfolio\\projects\\_03_factor_selection\\factory\\experiments.yaml'

        test_configs = _load_file('D:\\lqs\\codeAbout\\py\\Quantitative\\quant_research_portfolio\\projects\\_03_factor_selection\\factory\\experiments.yaml')

        # åˆ›å»ºå¹¶å‘æµ‹è¯•å™¨
        # å»ºè®®å¹¶å‘æ•°ä¸è¦è¶…è¿‡CPUæ ¸å¿ƒæ•°çš„75%
        import multiprocessing
        max_workers = min(3, max(1, multiprocessing.cpu_count() // 4))
        
        logger.info(f"ğŸ”§ ç³»ç»ŸCPUæ ¸å¿ƒæ•°: {multiprocessing.cpu_count()}, ä½¿ç”¨å¹¶å‘æ•°: {max_workers}")
        
        tester = ConcurrentFactorTester(
            config_path=str(config_path),
            experiments_path=str(experiments_path), 
            max_workers=max_workers
        )
        
        # æ‰§è¡Œå¹¶å‘æµ‹è¯•
        logger.info(f"ğŸš€ å¼€å§‹å¹¶å‘æµ‹è¯• {len(test_configs)} ä¸ªå› å­...")
        start_time = time.time()
        
        results = tester.run_batch_testing(test_configs)
        
        total_time = time.time() - start_time
        logger.info(f"ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ! æ€»è€—æ—¶: {total_time:.1f}ç§’")
        
        # ä¿å­˜ç»“æœ
        tester.save_results()
        
        return results
        
    except Exception as e:
        logger.error(f"å¹¶å‘æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        traceback.print_exc()
        raise


if __name__ == "__main__":
    results = main()