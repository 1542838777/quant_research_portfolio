"""
æ»šåŠ¨ICç›®å½•æ¸…ç†å·¥å…·

åŠŸèƒ½ï¼šæ‰¹é‡åˆ é™¤ä¸åŒå› å­ç›®å½•ä¸‹çš„rolling_icæ–‡ä»¶å¤¹
è·¯å¾„æ¨¡å¼ï¼š{base_path}/{stock_pool}/{factor_name}/{calcu_type}/{version}/rolling_ic
"""

import os
import shutil
from pathlib import Path
from typing import List, Optional, Tuple
import argparse
from quant_lib.config.logger_config import setup_logger

logger = setup_logger(__name__)


class RollingICCleaner:
    """æ»šåŠ¨ICæ¸…ç†å™¨"""
    
    def __init__(self, base_path: str = None):
        """
        åˆå§‹åŒ–æ¸…ç†å™¨
        
        Args:
            base_path: åŸºç¡€è·¯å¾„ï¼Œé»˜è®¤ä¸ºé¡¹ç›®å·¥ä½œè·¯å¾„
        """
        if base_path is None:
            self.base_path = Path(r"/projects/_03_factor_selection/workspace/result")
        else:
            self.base_path = Path(base_path)
        
        if not self.base_path.exists():
            raise ValueError(f"åŸºç¡€è·¯å¾„ä¸å­˜åœ¨: {self.base_path}")
    
    def scan_rolling_ic_directories(
        self,
        stock_pools: Optional[List[str]] = None,
        factor_names: Optional[List[str]] = None,
        calcu_types: Optional[List[str]] = None,
        versions: Optional[List[str]] = None
    ) -> List[Path]:
        """
        æ‰«æç¬¦åˆæ¡ä»¶çš„rolling_icç›®å½•
        
        Args:
            stock_pools: è‚¡ç¥¨æ± åˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºæ‰€æœ‰
            factor_names: å› å­åç§°åˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºæ‰€æœ‰  
            calcu_types: è®¡ç®—ç±»å‹åˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºæ‰€æœ‰
            versions: ç‰ˆæœ¬åˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºæ‰€æœ‰
            
        Returns:
            List[Path]: æ‰¾åˆ°çš„rolling_icç›®å½•è·¯å¾„åˆ—è¡¨
        """
        rolling_ic_dirs = []
        
        logger.info(f"ğŸ” å¼€å§‹æ‰«ærolling_icç›®å½•: {self.base_path}")
        
        # éå†è‚¡ç¥¨æ± ç›®å½•
        for stock_pool_dir in self.base_path.iterdir():
            if not stock_pool_dir.is_dir():
                continue
                
            stock_pool = stock_pool_dir.name
            if stock_pools and stock_pool not in stock_pools:
                continue
                
            logger.debug(f"ğŸ“‚ æ‰«æè‚¡ç¥¨æ± : {stock_pool}")
            
            # éå†å› å­ç›®å½•
            for factor_dir in stock_pool_dir.iterdir():
                if not factor_dir.is_dir():
                    continue
                    
                factor_name = factor_dir.name
                if factor_names and factor_name not in factor_names:
                    continue
                    
                # éå†è®¡ç®—ç±»å‹ç›®å½•
                for calcu_type_dir in factor_dir.iterdir():
                    if not calcu_type_dir.is_dir():
                        continue
                        
                    calcu_type = calcu_type_dir.name
                    if calcu_types and calcu_type not in calcu_types:
                        continue
                        
                    # éå†ç‰ˆæœ¬ç›®å½•
                    for version_dir in calcu_type_dir.iterdir():
                        if not version_dir.is_dir():
                            continue
                            
                        version = version_dir.name
                        if versions and version not in versions:
                            continue
                            
                        # æ£€æŸ¥rolling_icç›®å½•
                        rolling_ic_dir = version_dir / "rolling_ic"
                        if rolling_ic_dir.exists() and rolling_ic_dir.is_dir():
                            rolling_ic_dirs.append(rolling_ic_dir)
                            logger.debug(f"  âœ“ æ‰¾åˆ°: {rolling_ic_dir}")
        
        logger.info(f"ğŸ“Š æ‰«æå®Œæˆï¼Œå…±æ‰¾åˆ° {len(rolling_ic_dirs)} ä¸ªrolling_icç›®å½•")
        return rolling_ic_dirs
    
    def delete_rolling_ic_directories(
        self,
        rolling_ic_dirs: List[Path],
        dry_run: bool = True
    ) -> Tuple[int, int, List[str]]:
        """
        åˆ é™¤rolling_icç›®å½•
        
        Args:
            rolling_ic_dirs: è¦åˆ é™¤çš„ç›®å½•åˆ—è¡¨
            dry_run: æ˜¯å¦ä¸ºè¯•è¿è¡Œæ¨¡å¼
            
        Returns:
            (æˆåŠŸæ•°é‡, å¤±è´¥æ•°é‡, é”™è¯¯ä¿¡æ¯åˆ—è¡¨)
        """
        success_count = 0
        failed_count = 0
        errors = []
        
        mode_text = "è¯•è¿è¡Œ" if dry_run else "å®é™…åˆ é™¤"
        logger.info(f"ğŸ—‘ï¸ å¼€å§‹{mode_text}ï¼Œå…± {len(rolling_ic_dirs)} ä¸ªç›®å½•")
        
        for i, rolling_ic_dir in enumerate(rolling_ic_dirs, 1):
            try:
                if dry_run:
                    # è¯•è¿è¡Œæ¨¡å¼ï¼Œåªè®°å½•ä½†ä¸å®é™…åˆ é™¤
                    file_count = sum(1 for _ in rolling_ic_dir.rglob('*') if _.is_file())
                    logger.info(f"  [{i:3d}] [è¯•è¿è¡Œ] {rolling_ic_dir} (åŒ…å« {file_count} ä¸ªæ–‡ä»¶)")
                    success_count += 1
                else:
                    # å®é™…åˆ é™¤æ¨¡å¼
                    if rolling_ic_dir.exists():
                        file_count = sum(1 for _ in rolling_ic_dir.rglob('*') if _.is_file())
                        shutil.rmtree(rolling_ic_dir)
                        logger.info(f"  [{i:3d}] [å·²åˆ é™¤] {rolling_ic_dir} (åˆ é™¤äº† {file_count} ä¸ªæ–‡ä»¶)")
                        success_count += 1
                    else:
                        logger.warning(f"  [{i:3d}] [è·³è¿‡] {rolling_ic_dir} (ç›®å½•ä¸å­˜åœ¨)")
                        
            except Exception as e:
                error_msg = f"åˆ é™¤å¤±è´¥ {rolling_ic_dir}: {e}"
                errors.append(error_msg)
                logger.error(f"  [{i:3d}] [å¤±è´¥] {error_msg}")
                failed_count += 1
        
        logger.info(f"âœ… {mode_text}å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {failed_count}")
        return success_count, failed_count, errors
    
    def cleanup_by_criteria(
        self,
        stock_pools: Optional[List[str]] = None,
        factor_names: Optional[List[str]] = None,
        calcu_types: Optional[List[str]] = None,
        versions: Optional[List[str]] = None,
        dry_run: bool = True
    ) -> Tuple[int, int, List[str]]:
        """
        æŒ‰æ¡ä»¶æ¸…ç†rolling_icç›®å½•
        
        Args:
            stock_pools: è‚¡ç¥¨æ± ç­›é€‰
            factor_names: å› å­åç§°ç­›é€‰
            calcu_types: è®¡ç®—ç±»å‹ç­›é€‰
            versions: ç‰ˆæœ¬ç­›é€‰
            dry_run: æ˜¯å¦ä¸ºè¯•è¿è¡Œ
            
        Returns:
            (æˆåŠŸæ•°é‡, å¤±è´¥æ•°é‡, é”™è¯¯ä¿¡æ¯åˆ—è¡¨)
        """
        # 1. æ‰«æç›®å½•
        rolling_ic_dirs = self.scan_rolling_ic_directories(
            stock_pools=stock_pools,
            factor_names=factor_names, 
            calcu_types=calcu_types,
            versions=versions
        )
        
        if not rolling_ic_dirs:
            logger.info("æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„rolling_icç›®å½•")
            return 0, 0, []
        
        # 2. æ‰§è¡Œåˆ é™¤
        return self.delete_rolling_ic_directories(rolling_ic_dirs, dry_run=dry_run)
    
    def cleanup_all_rolling_ic(self, dry_run: bool = True) -> Tuple[int, int, List[str]]:
        """
        æ¸…ç†æ‰€æœ‰rolling_icç›®å½•
        
        Args:
            dry_run: æ˜¯å¦ä¸ºè¯•è¿è¡Œ
            
        Returns:
            (æˆåŠŸæ•°é‡, å¤±è´¥æ•°é‡, é”™è¯¯ä¿¡æ¯åˆ—è¡¨)
        """
        return self.cleanup_by_criteria(dry_run=dry_run)
    
    def cleanup_by_factor_list(
        self,
        factor_names: List[str],
        calcu_type: str = "o2o",
        version: str = "20190328_20231231",
        stock_pool: str = "000906",
        dry_run: bool = True
    ) -> Tuple[int, int, List[str]]:
        """
        æŒ‰å› å­åˆ—è¡¨æ¸…ç†rolling_icç›®å½•
        
        Args:
            factor_names: å› å­åç§°åˆ—è¡¨
            calcu_type: è®¡ç®—ç±»å‹
            version: ç‰ˆæœ¬
            stock_pool: è‚¡ç¥¨æ± 
            dry_run: æ˜¯å¦ä¸ºè¯•è¿è¡Œ
            
        Returns:
            (æˆåŠŸæ•°é‡, å¤±è´¥æ•°é‡, é”™è¯¯ä¿¡æ¯åˆ—è¡¨)
        """
        return self.cleanup_by_criteria(
            stock_pools=[stock_pool],
            factor_names=factor_names,
            calcu_types=[calcu_type],
            versions=[version],
            dry_run=dry_run
        )


def main():
    """å‘½ä»¤è¡Œä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æ»šåŠ¨ICç›®å½•æ¸…ç†å·¥å…·")
    parser.add_argument("--base-path", type=str, help="åŸºç¡€è·¯å¾„")
    parser.add_argument("--stock-pools", nargs="+", help="è‚¡ç¥¨æ± åˆ—è¡¨")
    parser.add_argument("--factors", nargs="+", help="å› å­åç§°åˆ—è¡¨")
    parser.add_argument("--calcu-types", nargs="+", help="è®¡ç®—ç±»å‹åˆ—è¡¨")
    parser.add_argument("--versions", nargs="+", help="ç‰ˆæœ¬åˆ—è¡¨")
    parser.add_argument("--dry-run", action="store_true", default=True, help="è¯•è¿è¡Œæ¨¡å¼")
    parser.add_argument("--execute", action="store_true", help="å®é™…æ‰§è¡Œåˆ é™¤")
    
    args = parser.parse_args()
    
    # åˆ›å»ºæ¸…ç†å™¨
    cleaner = RollingICCleaner(base_path=args.base_path)
    
    # æ‰§è¡Œæ¸…ç†
    dry_run = not args.execute
    success, failed, errors = cleaner.cleanup_by_criteria(
        stock_pools=args.stock_pools,
        factor_names=args.factors,
        calcu_types=args.calcu_types,
        versions=args.versions,
        dry_run=dry_run
    )
    
    if errors:
        logger.error("é”™è¯¯è¯¦æƒ…:")
        for error in errors:
            logger.error(f"  - {error}")


if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    import pandas as pd
    
    logger.info("=== æ»šåŠ¨ICæ¸…ç†å·¥å…·ç¤ºä¾‹ ===")
    
    # åˆ›å»ºæ¸…ç†å™¨
    cleaner = RollingICCleaner()
    
    # ç¤ºä¾‹1: æ¸…ç†æŒ‡å®šå› å­
    # logger.info("\n--- ç¤ºä¾‹1: æ¸…ç†æŒ‡å®šå› å­ ---")
    # test_factors = ["volatility_40d", "momentum_60d", "amihud_liquidity"]
    # success, failed, errors = cleaner.cleanup_by_factor_list(
    #     factor_names=test_factors,
    #     dry_run=False  # è¯•è¿è¡Œ
    # )
    #
    # ç¤ºä¾‹2: æ¸…ç†æ‰€æœ‰rolling_ic (è¯•è¿è¡Œ)
    logger.info("\n--- ç¤ºä¾‹2: æ¸…ç†æ‰€æœ‰rolling_ic (è¯•è¿è¡Œ) ---")
    success, failed, errors = cleaner.cleanup_all_rolling_ic(dry_run=False)
    #
    # # ç¤ºä¾‹3: ä»CSVè¯»å–å› å­å¹¶æ¸…ç†
    # logger.info("\n--- ç¤ºä¾‹3: ä»CSVè¯»å–å› å­å¹¶æ¸…ç† ---")
    # try:
    #     df = pd.read_csv(r'D:\lqs\codeAbout\py\Quantitative\quant_research_portfolio\projects\_03_factor_selection\factor_manager\selector\v3æœªç»è¿‡æ®‹å·®åŒ–ç‰ˆæœ¬.csv')
    #     all_factors = df['factor_name'].unique().tolist()
    #
    #     logger.info(f"ä»CSVè¯»å–åˆ° {len(all_factors)} ä¸ªå› å­")
    #
    #     # è¯•è¿è¡Œæ¨¡å¼æ¸…ç†æ‰€æœ‰å› å­
    #     success, failed, errors = cleaner.cleanup_by_factor_list(
    #         factor_names=all_factors[:5],  # å…ˆæµ‹è¯•å‰5ä¸ª
    #         dry_run=True
    #     )
    #
    #     if errors:
    #         logger.warning("æ¸…ç†è¿‡ç¨‹ä¸­å‘ç°é”™è¯¯:")
    #         for error in errors:
    #             logger.warning(f"  - {error}")
    #
    #     # å®é™…æ‰§è¡Œéœ€è¦å°†dry_runè®¾ä¸ºFalse
    #     # success, failed, errors = cleaner.cleanup_by_factor_list(
    #     #     factor_names=all_factors,
    #     #     dry_run=False  # å®é™…åˆ é™¤
    #     # )
    #
    # except Exception as e:
    #     logger.error(f"è¯»å–CSVæ–‡ä»¶å¤±è´¥: {e}")
    #
    # logger.info("\n=== æ¸…ç†å·¥å…·æ¼”ç¤ºå®Œæˆ ===")
    # logger.info("ğŸ’¡ æç¤º: å°† dry_run=False ä»¥å®é™…æ‰§è¡Œåˆ é™¤æ“ä½œ")